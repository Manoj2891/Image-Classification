{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQOMthDBVhNV",
        "colab_type": "text"
      },
      "source": [
        "# **FACE CLASSIFIER**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbQQvwCeVpjC",
        "colab_type": "text"
      },
      "source": [
        "**Project Overview and Objective:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaEwYBnBS_Di",
        "colab_type": "text"
      },
      "source": [
        "The main purpose of this project was to build a CNN model that would identify the human faces correctly and act as a classifier. I used the VGG-16, Inception v3 , and a model built from scratch to train the model for this multiclass problem. I used accuracy as a metric to justify the model performance which can be defined as:\n",
        "\n",
        "Accuracy=Number of correclty predicted images/Total number of tested images×100%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxhoEpU6Xq3Q",
        "colab_type": "text"
      },
      "source": [
        "**Dataset Description:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1OM4DscXyI0",
        "colab_type": "text"
      },
      "source": [
        "The image data that was used for this problem is Human Face Images for building Face Classifier. It conists of face images of 109 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5g-nG4HCYC5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "2b572b99-c17a-4c40-8510-2f6e72b39fdb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-srnKmdkYkd5",
        "colab_type": "text"
      },
      "source": [
        "Loading Libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysReBALLCq4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os\n",
        "PATH = os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQO-h_9jRR0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WAKjS1KRT8P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8fff71c0-1df9-472a-da53-e891e0552754"
      },
      "source": [
        "DATA_PATH = os.path.join(PATH, '/content/drive/My Drive/Task 4/male')\n",
        "data_dir_list = sorted(os.listdir(DATA_PATH))\n",
        "print(data_dir_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['9326871', '9332898', '9338446', '9338454', '9338462', '9338489', '9338497', '9338519', '9338527', '9338543', '9414649', '9416994', 'admars', 'ahodki', 'ajflem', 'ajones', 'ajsega', 'akatsi', 'ambarw', 'asheal', 'bplyce', 'cchris', 'ccjame', 'cferdo', 'cgboyc', 'cjcarr', 'cjdenn', 'cjsake', 'cmkirk', 'csanch', 'cshubb', 'cwchoi', 'dagran', 'dakram', 'dcbowe', 'dioann', 'djbirc', 'djhugh', 'djmart', 'dmwest', 'gdhatc', 'ggeorg', 'ggrego', 'gjhero', 'gjnorm', 'gmwate', 'gpapaz', 'gpsmit', 'gsreas', 'irdrew', 'jabins', 'jagrif', 'jdbenm', 'jgloma', 'jlemon', 'jmedin', 'jrtobi', 'kaatki', 'kdjone', 'khchan', 'khughe', 'kjwith', 'lejnno', 'maasht', 'mberdo', 'mdpove', 'mefait', 'mhwill', 'miaduc', 'mjhans', 'mpetti', 'muthay', 'nahaig', 'ndbank', 'ndhagu', 'nhrams', 'njmoor', 'npmitc', 'nrclar', 'nrrbar', 'ohpark', 'pacole', 'pmives', 'pshurr', 'pspliu', 'ptnich', 'rarobi', 'rgharr', 'rgspru', 'rjlabr', 'rlocke', 'rmcoll', 'rmpugh', 'rnpwil', 'rrowle', 'rsanti', 'saduah', 'saedwa', 'sidick', 'sjbeck', 'skumar', 'smrobb', 'spletc', 'svkriz', 'swewin', 'swsmit', 'vpsavo', 'whussa', 'wjalbe']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhCQIKjeRbxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows=224\n",
        "img_cols=224\n",
        "num_channel=3\n",
        "\n",
        "num_epoch=10\n",
        "batch_size=512\n",
        "\n",
        "img_data_list=[]\n",
        "classes_names_list=[]\n",
        "labels_index = {}  \n",
        "labels = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X98sSQDwSgoP",
        "colab_type": "text"
      },
      "source": [
        "**Loading Data and Preprocessing:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgQKf9yBRfEJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e92b44f6-ae54-4818-f076-2f7a775dfc6f"
      },
      "source": [
        "import cv2\n",
        "\n",
        "for dataset in data_dir_list:\n",
        "    classes_names_list.append(dataset) \n",
        "    print ('Loading images from {} folder\\n'.format(dataset)) \n",
        "    label_id = len(labels_index)\n",
        "    labels_index[dataset] = label_id\n",
        "    img_list=os.listdir(DATA_PATH+'/'+ dataset)\n",
        "    for img in img_list:\n",
        "        input_img=cv2.imread(DATA_PATH + '/'+ dataset + '/'+ img )\n",
        "        input_img_resize=cv2.resize(input_img,(img_rows, img_cols))\n",
        "        img_data_list.append(input_img_resize)\n",
        "        labels.append(label_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading images from 9326871 folder\n",
            "\n",
            "Loading images from 9332898 folder\n",
            "\n",
            "Loading images from 9338446 folder\n",
            "\n",
            "Loading images from 9338454 folder\n",
            "\n",
            "Loading images from 9338462 folder\n",
            "\n",
            "Loading images from 9338489 folder\n",
            "\n",
            "Loading images from 9338497 folder\n",
            "\n",
            "Loading images from 9338519 folder\n",
            "\n",
            "Loading images from 9338527 folder\n",
            "\n",
            "Loading images from 9338543 folder\n",
            "\n",
            "Loading images from 9414649 folder\n",
            "\n",
            "Loading images from 9416994 folder\n",
            "\n",
            "Loading images from admars folder\n",
            "\n",
            "Loading images from ahodki folder\n",
            "\n",
            "Loading images from ajflem folder\n",
            "\n",
            "Loading images from ajones folder\n",
            "\n",
            "Loading images from ajsega folder\n",
            "\n",
            "Loading images from akatsi folder\n",
            "\n",
            "Loading images from ambarw folder\n",
            "\n",
            "Loading images from asheal folder\n",
            "\n",
            "Loading images from bplyce folder\n",
            "\n",
            "Loading images from cchris folder\n",
            "\n",
            "Loading images from ccjame folder\n",
            "\n",
            "Loading images from cferdo folder\n",
            "\n",
            "Loading images from cgboyc folder\n",
            "\n",
            "Loading images from cjcarr folder\n",
            "\n",
            "Loading images from cjdenn folder\n",
            "\n",
            "Loading images from cjsake folder\n",
            "\n",
            "Loading images from cmkirk folder\n",
            "\n",
            "Loading images from csanch folder\n",
            "\n",
            "Loading images from cshubb folder\n",
            "\n",
            "Loading images from cwchoi folder\n",
            "\n",
            "Loading images from dagran folder\n",
            "\n",
            "Loading images from dakram folder\n",
            "\n",
            "Loading images from dcbowe folder\n",
            "\n",
            "Loading images from dioann folder\n",
            "\n",
            "Loading images from djbirc folder\n",
            "\n",
            "Loading images from djhugh folder\n",
            "\n",
            "Loading images from djmart folder\n",
            "\n",
            "Loading images from dmwest folder\n",
            "\n",
            "Loading images from gdhatc folder\n",
            "\n",
            "Loading images from ggeorg folder\n",
            "\n",
            "Loading images from ggrego folder\n",
            "\n",
            "Loading images from gjhero folder\n",
            "\n",
            "Loading images from gjnorm folder\n",
            "\n",
            "Loading images from gmwate folder\n",
            "\n",
            "Loading images from gpapaz folder\n",
            "\n",
            "Loading images from gpsmit folder\n",
            "\n",
            "Loading images from gsreas folder\n",
            "\n",
            "Loading images from irdrew folder\n",
            "\n",
            "Loading images from jabins folder\n",
            "\n",
            "Loading images from jagrif folder\n",
            "\n",
            "Loading images from jdbenm folder\n",
            "\n",
            "Loading images from jgloma folder\n",
            "\n",
            "Loading images from jlemon folder\n",
            "\n",
            "Loading images from jmedin folder\n",
            "\n",
            "Loading images from jrtobi folder\n",
            "\n",
            "Loading images from kaatki folder\n",
            "\n",
            "Loading images from kdjone folder\n",
            "\n",
            "Loading images from khchan folder\n",
            "\n",
            "Loading images from khughe folder\n",
            "\n",
            "Loading images from kjwith folder\n",
            "\n",
            "Loading images from lejnno folder\n",
            "\n",
            "Loading images from maasht folder\n",
            "\n",
            "Loading images from mberdo folder\n",
            "\n",
            "Loading images from mdpove folder\n",
            "\n",
            "Loading images from mefait folder\n",
            "\n",
            "Loading images from mhwill folder\n",
            "\n",
            "Loading images from miaduc folder\n",
            "\n",
            "Loading images from mjhans folder\n",
            "\n",
            "Loading images from mpetti folder\n",
            "\n",
            "Loading images from muthay folder\n",
            "\n",
            "Loading images from nahaig folder\n",
            "\n",
            "Loading images from ndbank folder\n",
            "\n",
            "Loading images from ndhagu folder\n",
            "\n",
            "Loading images from nhrams folder\n",
            "\n",
            "Loading images from njmoor folder\n",
            "\n",
            "Loading images from npmitc folder\n",
            "\n",
            "Loading images from nrclar folder\n",
            "\n",
            "Loading images from nrrbar folder\n",
            "\n",
            "Loading images from ohpark folder\n",
            "\n",
            "Loading images from pacole folder\n",
            "\n",
            "Loading images from pmives folder\n",
            "\n",
            "Loading images from pshurr folder\n",
            "\n",
            "Loading images from pspliu folder\n",
            "\n",
            "Loading images from ptnich folder\n",
            "\n",
            "Loading images from rarobi folder\n",
            "\n",
            "Loading images from rgharr folder\n",
            "\n",
            "Loading images from rgspru folder\n",
            "\n",
            "Loading images from rjlabr folder\n",
            "\n",
            "Loading images from rlocke folder\n",
            "\n",
            "Loading images from rmcoll folder\n",
            "\n",
            "Loading images from rmpugh folder\n",
            "\n",
            "Loading images from rnpwil folder\n",
            "\n",
            "Loading images from rrowle folder\n",
            "\n",
            "Loading images from rsanti folder\n",
            "\n",
            "Loading images from saduah folder\n",
            "\n",
            "Loading images from saedwa folder\n",
            "\n",
            "Loading images from sidick folder\n",
            "\n",
            "Loading images from sjbeck folder\n",
            "\n",
            "Loading images from skumar folder\n",
            "\n",
            "Loading images from smrobb folder\n",
            "\n",
            "Loading images from spletc folder\n",
            "\n",
            "Loading images from svkriz folder\n",
            "\n",
            "Loading images from swewin folder\n",
            "\n",
            "Loading images from swsmit folder\n",
            "\n",
            "Loading images from vpsavo folder\n",
            "\n",
            "Loading images from whussa folder\n",
            "\n",
            "Loading images from wjalbe folder\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUNrtD4mSK1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "89fa8c28-c77e-4c8c-92ab-e7f2e6f6249f"
      },
      "source": [
        "labels_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'9326871': 0,\n",
              " '9332898': 1,\n",
              " '9338446': 2,\n",
              " '9338454': 3,\n",
              " '9338462': 4,\n",
              " '9338489': 5,\n",
              " '9338497': 6,\n",
              " '9338519': 7,\n",
              " '9338527': 8,\n",
              " '9338543': 9,\n",
              " '9414649': 10,\n",
              " '9416994': 11,\n",
              " 'admars': 12,\n",
              " 'ahodki': 13,\n",
              " 'ajflem': 14,\n",
              " 'ajones': 15,\n",
              " 'ajsega': 16,\n",
              " 'akatsi': 17,\n",
              " 'ambarw': 18,\n",
              " 'asheal': 19,\n",
              " 'bplyce': 20,\n",
              " 'cchris': 21,\n",
              " 'ccjame': 22,\n",
              " 'cferdo': 23,\n",
              " 'cgboyc': 24,\n",
              " 'cjcarr': 25,\n",
              " 'cjdenn': 26,\n",
              " 'cjsake': 27,\n",
              " 'cmkirk': 28,\n",
              " 'csanch': 29,\n",
              " 'cshubb': 30,\n",
              " 'cwchoi': 31,\n",
              " 'dagran': 32,\n",
              " 'dakram': 33,\n",
              " 'dcbowe': 34,\n",
              " 'dioann': 35,\n",
              " 'djbirc': 36,\n",
              " 'djhugh': 37,\n",
              " 'djmart': 38,\n",
              " 'dmwest': 39,\n",
              " 'gdhatc': 40,\n",
              " 'ggeorg': 41,\n",
              " 'ggrego': 42,\n",
              " 'gjhero': 43,\n",
              " 'gjnorm': 44,\n",
              " 'gmwate': 45,\n",
              " 'gpapaz': 46,\n",
              " 'gpsmit': 47,\n",
              " 'gsreas': 48,\n",
              " 'irdrew': 49,\n",
              " 'jabins': 50,\n",
              " 'jagrif': 51,\n",
              " 'jdbenm': 52,\n",
              " 'jgloma': 53,\n",
              " 'jlemon': 54,\n",
              " 'jmedin': 55,\n",
              " 'jrtobi': 56,\n",
              " 'kaatki': 57,\n",
              " 'kdjone': 58,\n",
              " 'khchan': 59,\n",
              " 'khughe': 60,\n",
              " 'kjwith': 61,\n",
              " 'lejnno': 62,\n",
              " 'maasht': 63,\n",
              " 'mberdo': 64,\n",
              " 'mdpove': 65,\n",
              " 'mefait': 66,\n",
              " 'mhwill': 67,\n",
              " 'miaduc': 68,\n",
              " 'mjhans': 69,\n",
              " 'mpetti': 70,\n",
              " 'muthay': 71,\n",
              " 'nahaig': 72,\n",
              " 'ndbank': 73,\n",
              " 'ndhagu': 74,\n",
              " 'nhrams': 75,\n",
              " 'njmoor': 76,\n",
              " 'npmitc': 77,\n",
              " 'nrclar': 78,\n",
              " 'nrrbar': 79,\n",
              " 'ohpark': 80,\n",
              " 'pacole': 81,\n",
              " 'pmives': 82,\n",
              " 'pshurr': 83,\n",
              " 'pspliu': 84,\n",
              " 'ptnich': 85,\n",
              " 'rarobi': 86,\n",
              " 'rgharr': 87,\n",
              " 'rgspru': 88,\n",
              " 'rjlabr': 89,\n",
              " 'rlocke': 90,\n",
              " 'rmcoll': 91,\n",
              " 'rmpugh': 92,\n",
              " 'rnpwil': 93,\n",
              " 'rrowle': 94,\n",
              " 'rsanti': 95,\n",
              " 'saduah': 96,\n",
              " 'saedwa': 97,\n",
              " 'sidick': 98,\n",
              " 'sjbeck': 99,\n",
              " 'skumar': 100,\n",
              " 'smrobb': 101,\n",
              " 'spletc': 102,\n",
              " 'svkriz': 103,\n",
              " 'swewin': 104,\n",
              " 'swsmit': 105,\n",
              " 'vpsavo': 106,\n",
              " 'whussa': 107,\n",
              " 'wjalbe': 108}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi3f8fvoZNNw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc8f6d63-b45a-4339-caaf-1e1b82876395"
      },
      "source": [
        "len(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2180"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CdsV_ECZRxg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c57d2ce-715a-4a2a-9275-fef5f408dc58"
      },
      "source": [
        "len(labels_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccEnhdsUZUnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "img_data = np.array(img_data_list)\n",
        "img_data = img_data.astype('float32')\n",
        "img_data /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu20SeVxZaZP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c61632dd-9454-499c-f3fb-c49f191dd869"
      },
      "source": [
        "print (img_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2180, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k-zlYuZZe2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_of_samples = img_data.shape[0]\n",
        "input_shape = img_data[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMbiMnBPZhxh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51992053-00de-4632-8ed9-9d2605781c14"
      },
      "source": [
        "num_classes = len(classes_names_list)\n",
        "print(num_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7VbtjNgZjw1",
        "colab_type": "text"
      },
      "source": [
        "**Convert class labels to numberic using one-hot encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHLMB-piZjUp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c4b0a1b-f737-4036-c941-2f8ee444e3e0"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "classes = to_categorical(labels, num_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0lPqRCrZrdS",
        "colab_type": "text"
      },
      "source": [
        "**Shuffle the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kURbxlRlZnoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "X, Y = shuffle(img_data, classes, random_state=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJZx4qMkZtF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2odVQM4dblTE",
        "colab_type": "text"
      },
      "source": [
        "**CNN Model:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6mbIT0sbwJR",
        "colab_type": "text"
      },
      "source": [
        "I was using Transfer Learning with VGG-16 architecture,InceptionV3 and weights as a base model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJEkhr2ecg9v",
        "colab_type": "text"
      },
      "source": [
        "**VGG-16**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lYjsFwlZ2De",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nBhkNfQaLsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_input = Input(shape=(img_rows, img_cols, num_channel))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsMTpzudaNpq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7ae215d0-d527-4da9-8e11-a87e9e076d92"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "model = VGG16(input_tensor = image_input,include_top=True,weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 22s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL1yMSzxaVwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "7bd61bbb-ebf1-48cb-9a7c-7aa31005a876"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xOODSbNafeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last_layer = model.get_layer('fc2').output\n",
        "out = Dense(num_classes, activation='softmax', name='output')(last_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnqSm_KCaiV8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "13c205cf-ed88-4989-c143-b32a14ca7e8f"
      },
      "source": [
        "from keras.models import Model\n",
        "\n",
        "custom_vgg_model = Model(image_input, out)\n",
        "custom_vgg_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 109)               446573    \n",
            "=================================================================\n",
            "Total params: 134,707,117\n",
            "Trainable params: 134,707,117\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVQsmhAJbChm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b96a66f5-92fd-4130-82e8-7e5c6d532d3e"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1744, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bToGWehtakpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in custom_vgg_model.layers[:-1]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udJihTGSao3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_vgg_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVZhd1dFaq6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9812be77-d506-464f-8f67-22e65526e611"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhXXhKs0auEZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "becd7874-f7eb-4d1d-8e69-f49c244dff73"
      },
      "source": [
        "custom_vgg_model.fit(X_train, y_train, batch_size=batch_size, epochs=20, verbose=1, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1744 samples, validate on 436 samples\n",
            "Epoch 1/20\n",
            "1744/1744 [==============================] - 376s 216ms/step - loss: 5.2377 - accuracy: 0.0075 - val_loss: 4.9234 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "1744/1744 [==============================] - 377s 216ms/step - loss: 4.8059 - accuracy: 0.0361 - val_loss: 4.5406 - val_accuracy: 0.1170\n",
            "Epoch 3/20\n",
            "1744/1744 [==============================] - 376s 216ms/step - loss: 4.4344 - accuracy: 0.0808 - val_loss: 4.1748 - val_accuracy: 0.0803\n",
            "Epoch 4/20\n",
            "1744/1744 [==============================] - 383s 220ms/step - loss: 4.1031 - accuracy: 0.1416 - val_loss: 3.9238 - val_accuracy: 0.3372\n",
            "Epoch 5/20\n",
            "1744/1744 [==============================] - 372s 213ms/step - loss: 3.8285 - accuracy: 0.3469 - val_loss: 3.7554 - val_accuracy: 0.2454\n",
            "Epoch 6/20\n",
            "1744/1744 [==============================] - 374s 214ms/step - loss: 3.5918 - accuracy: 0.3589 - val_loss: 3.4077 - val_accuracy: 0.4725\n",
            "Epoch 7/20\n",
            "1744/1744 [==============================] - 370s 212ms/step - loss: 3.3274 - accuracy: 0.5315 - val_loss: 3.2064 - val_accuracy: 0.5711\n",
            "Epoch 8/20\n",
            "1744/1744 [==============================] - 372s 213ms/step - loss: 3.1236 - accuracy: 0.6319 - val_loss: 3.0042 - val_accuracy: 0.7133\n",
            "Epoch 9/20\n",
            "1744/1744 [==============================] - 371s 213ms/step - loss: 2.9100 - accuracy: 0.7374 - val_loss: 2.7816 - val_accuracy: 0.7706\n",
            "Epoch 10/20\n",
            "1744/1744 [==============================] - 372s 213ms/step - loss: 2.7217 - accuracy: 0.7460 - val_loss: 2.5979 - val_accuracy: 0.8028\n",
            "Epoch 11/20\n",
            "1744/1744 [==============================] - 373s 214ms/step - loss: 2.5207 - accuracy: 0.8366 - val_loss: 2.4162 - val_accuracy: 0.8807\n",
            "Epoch 12/20\n",
            "1744/1744 [==============================] - 376s 216ms/step - loss: 2.3647 - accuracy: 0.8721 - val_loss: 2.2640 - val_accuracy: 0.9037\n",
            "Epoch 13/20\n",
            "1744/1744 [==============================] - 372s 213ms/step - loss: 2.1906 - accuracy: 0.8893 - val_loss: 2.1439 - val_accuracy: 0.8922\n",
            "Epoch 14/20\n",
            "1744/1744 [==============================] - 373s 214ms/step - loss: 2.0368 - accuracy: 0.9197 - val_loss: 1.9324 - val_accuracy: 0.9564\n",
            "Epoch 15/20\n",
            "1744/1744 [==============================] - 372s 213ms/step - loss: 1.8926 - accuracy: 0.9444 - val_loss: 1.8409 - val_accuracy: 0.9541\n",
            "Epoch 16/20\n",
            "1744/1744 [==============================] - 372s 214ms/step - loss: 1.7638 - accuracy: 0.9472 - val_loss: 1.7132 - val_accuracy: 0.9427\n",
            "Epoch 17/20\n",
            "1744/1744 [==============================] - 375s 215ms/step - loss: 1.6389 - accuracy: 0.9610 - val_loss: 1.5818 - val_accuracy: 0.9564\n",
            "Epoch 18/20\n",
            "1744/1744 [==============================] - 376s 216ms/step - loss: 1.5247 - accuracy: 0.9679 - val_loss: 1.4764 - val_accuracy: 0.9725\n",
            "Epoch 19/20\n",
            "1744/1744 [==============================] - 374s 214ms/step - loss: 1.4233 - accuracy: 0.9765 - val_loss: 1.3555 - val_accuracy: 0.9885\n",
            "Epoch 20/20\n",
            "1744/1744 [==============================] - 374s 214ms/step - loss: 1.3296 - accuracy: 0.9903 - val_loss: 1.2847 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7effffa9add8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfwpUe8-ax6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train_pred = custom_vgg_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8UiL8SN6Amu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "c9ebcaed-4832-4651-dd42-161a36a4ab2a"
      },
      "source": [
        "y_train_pred = np.argmax(Y_train_pred, axis=1)\n",
        "print(y_train_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 53  23  48  59  92  66  50  64  82  71  31  38  97  99 104  64 104  52\n",
            "  67  16  93  65   4   3  93  66  12  85  55  32  77 106  27  41  27  89\n",
            " 107  97   4 101  75   0  63  73  30  60  43 102  34   5  90  53  92  93\n",
            "  90  54  96   4  91  30  57  85  94  96  18 106  28 105  47  24  76  57\n",
            "  61  77  93  41  40 107  58  79  51  39  46  40  21  34   2  71  92  25\n",
            "   4  40  43  95   6  11  90  44 106  54  62  87  23  60  20  44   0  44\n",
            " 104  71  73  59  37  45  27  32   4   5  26  79  56  69  69  32  30  49\n",
            "  13  94  88   2  11 106 106  22  13  14  53  45  44  69  50  27 106  59\n",
            "  88  54  85  93  41  34  75  43  74   5  82 102  16  69  30  44 107  73\n",
            "  41   4  55  24  76  42  84 103  43  35  47  15  81  61  53  41  95   5\n",
            "   6  88  88  29  15 108  58  59   1  53  18  30  56  52  50  42  72  27\n",
            "  86  23  86  31  86  65  49  55  52  19   7  29   7  45 102  59  97  94\n",
            "  23  22 103  73   1  24  75  58  97   3  82  91   6  71  70  98  90  16\n",
            "  84  63  37   2  67  43  31  73  94  80  80  10  41  85   7 102  49  41\n",
            " 105  72  52  27  79  48  68  72  48   6   5  65  20  76  58  98  92  58\n",
            " 101 102  72  26  80  68   9  13   3  75  67  76  92  60  18 106  38   8\n",
            " 101  42  58  80  66  18  38 103  42  26  63  19  71  52  87  20  28  23\n",
            "  37 101  96  63   1   1  56  80  79 100  15  29  63  17  27  26  30   2\n",
            "  74  24  40  78  86  55  26  36   8  55  41  26  68   6  64  86  13  93\n",
            "   5  84 100  94  88 106  14  11  61  69  92  76   0  25  34  17  98  75\n",
            "  60  54 101  39  68  36  67  52  37  38  39  51   4 107  12  37  47  16\n",
            "   2  45  52  90  98  94  27  36 100  60  16  21 105  60  61  98  55  54\n",
            "  84  10  53  34  88  77  65  69  78  77  43  32  98  39  40  32   6  15\n",
            "  84  10  33  11 102   7  36 108  39  12  20  53  20 100 104  51  71  71\n",
            "  93  44  43  46]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBEu7iDC9DUh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1386669f-5202-495f-c2df-dec62fc7076b"
      },
      "source": [
        "(loss, accuracy) = custom_vgg_model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
        "\n",
        "print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r436/436 [==============================] - 73s 167ms/step\n",
            "[INFO] loss=1.2847, accuracy: 100.0000%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLgAX4oK-R-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFGnjvw9IX17",
        "colab_type": "text"
      },
      "source": [
        "**InceptionV3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pkw0p-MMcOa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import InceptionV3\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Anwncb3_c7M0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "801de45d-e37e-4f39-80ec-98eace872b2b"
      },
      "source": [
        "model1 = InceptionV3(input_tensor = image_input,include_top=False,weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re-RTVEZc_NS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "699645e1-a405-4749-b0ff-b87b3744656e"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 54, 54, 80)   240         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 54, 54, 80)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 52, 52, 192)  138240      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 52, 52, 192)  576         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 52, 52, 192)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 25, 25, 64)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 25, 25, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 25, 25, 96)   55296       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 25, 25, 48)   144         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 25, 25, 48)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 25, 25, 64)   76800       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 25, 25, 96)   82944       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 25, 25, 64)   192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 25, 25, 96)   288         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 25, 25, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 25, 25, 96)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_6[0][0]               \n",
            "                                                                 activation_8[0][0]               \n",
            "                                                                 activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 25, 25, 64)   192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 25, 25, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 25, 25, 96)   55296       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 25, 25, 48)   144         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 25, 25, 48)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 25, 25, 64)   76800       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 25, 25, 96)   82944       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_13[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 25, 25, 96)   55296       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 25, 25, 48)   144         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 25, 25, 48)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 25, 25, 64)   76800       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 25, 25, 96)   82944       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 25, 25, 64)   192         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 25, 25, 64)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_20[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 25, 25, 64)   192         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 25, 25, 64)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 25, 25, 96)   55296       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 25, 25, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 25, 25, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 12, 12, 96)   82944       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 12, 12, 384)  1152        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 12, 12, 96)   288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 384)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 96)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_27[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 12, 12, 128)  114688      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 12, 12, 128)  384         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 128)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 12, 12, 192)  172032      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 12, 12, 192)  172032      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 12, 12, 192)  576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 192)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 192)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_31[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 12, 12, 160)  179200      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 12, 12, 160)  480         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 12, 12, 160)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 12, 12, 160)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 12, 12, 192)  215040      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 12, 12, 192)  215040      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 12, 12, 192)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_41[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 12, 12, 160)  179200      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 12, 12, 160)  480         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 12, 12, 160)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 12, 12, 160)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 12, 12, 192)  215040      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 12, 12, 192)  215040      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 12, 12, 192)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_51[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "                                                                 activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 12, 12, 192)  258048      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_61[0][0]              \n",
            "                                                                 activation_64[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "                                                                 activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 12, 12, 192)  258048      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 5, 5, 320)    552960      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 5, 5, 192)    331776      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 5, 5, 320)    960         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 5, 5, 192)    576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 5, 5, 320)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 5, 5, 192)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_72[0][0]              \n",
            "                                                                 activation_76[0][0]              \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 5, 5, 448)    1344        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 5, 5, 448)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 5, 5, 384)    1548288     activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 5, 5, 320)    960         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 5, 5, 384)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 5, 5, 192)    576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 5, 5, 320)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_79[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_83[0][0]              \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 5, 5, 192)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_77[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 5, 5, 448)    1344        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 5, 5, 448)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 5, 5, 384)    1548288     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 5, 5, 384)    1152        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 5, 5, 384)    1152        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 5, 5, 320)    960         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 5, 5, 384)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 5, 5, 384)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 5, 5, 192)    576         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 5, 5, 320)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_88[0][0]              \n",
            "                                                                 activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_92[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 5, 5, 192)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_86[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_94[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZpJT9PgdNV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last_layer = model1.get_layer('mixed10').output\n",
        "x = GlobalAveragePooling2D(name='avg_pool')(last_layer)\n",
        "out = Dense(num_classes, activation='softmax', name='output')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFR24AIwdqLY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "676ca6b1-db7d-4ab9-8ab5-1c716532cf90"
      },
      "source": [
        "from keras.models import Model\n",
        "\n",
        "custom_incep_model = Model(image_input, out)\n",
        "custom_incep_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 54, 54, 80)   240         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 54, 54, 80)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 52, 52, 192)  138240      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 52, 52, 192)  576         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 52, 52, 192)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 25, 25, 64)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 25, 25, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 25, 25, 96)   55296       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 25, 25, 48)   144         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 25, 25, 48)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 25, 25, 64)   76800       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 25, 25, 96)   82944       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 25, 25, 64)   192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 25, 25, 96)   288         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 25, 25, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 25, 25, 96)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_6[0][0]               \n",
            "                                                                 activation_8[0][0]               \n",
            "                                                                 activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 25, 25, 64)   192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 25, 25, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 25, 25, 96)   55296       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 25, 25, 48)   144         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 25, 25, 48)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 25, 25, 64)   76800       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 25, 25, 96)   82944       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_13[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 25, 25, 96)   55296       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 25, 25, 48)   144         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 25, 25, 48)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 25, 25, 64)   76800       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 25, 25, 96)   82944       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 25, 25, 64)   192         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 25, 25, 64)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_20[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 25, 25, 64)   192         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 25, 25, 64)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 25, 25, 96)   55296       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 25, 25, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 25, 25, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 12, 12, 96)   82944       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 12, 12, 384)  1152        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 12, 12, 96)   288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 384)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 96)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_27[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 12, 12, 128)  114688      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 12, 12, 128)  384         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 128)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 12, 12, 192)  172032      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 12, 12, 192)  172032      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 12, 12, 192)  576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 192)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 192)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_31[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 12, 12, 160)  179200      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 12, 12, 160)  480         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 12, 12, 160)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 12, 12, 160)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 12, 12, 192)  215040      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 12, 12, 192)  215040      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 12, 12, 192)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_41[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 12, 12, 160)  179200      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 12, 12, 160)  480         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 12, 12, 160)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 12, 12, 160)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 12, 12, 192)  215040      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 12, 12, 192)  215040      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 12, 12, 192)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_51[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "                                                                 activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 12, 12, 192)  258048      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_61[0][0]              \n",
            "                                                                 activation_64[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "                                                                 activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 12, 12, 192)  258048      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 5, 5, 320)    552960      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 5, 5, 192)    331776      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 5, 5, 320)    960         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 5, 5, 192)    576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 5, 5, 320)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 5, 5, 192)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_72[0][0]              \n",
            "                                                                 activation_76[0][0]              \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 5, 5, 448)    1344        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 5, 5, 448)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 5, 5, 384)    1548288     activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 5, 5, 320)    960         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 5, 5, 384)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 5, 5, 192)    576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 5, 5, 320)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_79[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_83[0][0]              \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 5, 5, 192)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_77[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 5, 5, 448)    1344        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 5, 5, 448)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 5, 5, 384)    1548288     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 5, 5, 384)    1152        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 5, 5, 384)    1152        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 5, 5, 320)    960         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 5, 5, 384)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 5, 5, 384)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 5, 5, 192)    576         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 5, 5, 320)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_88[0][0]              \n",
            "                                                                 activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_92[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 5, 5, 192)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_86[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 109)          223341      avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 22,026,125\n",
            "Trainable params: 21,991,693\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVhVJypvdyhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in custom_incep_model.layers[:-2]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MeC_nSNd6Yd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_incep_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEf6DOpleEzL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "1d33a7af-756b-455d-fc2f-b5f006d2547a"
      },
      "source": [
        "custom_incep_model.fit(X_train, y_train, batch_size=batch_size, epochs=20, verbose=1, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1744 samples, validate on 436 samples\n",
            "Epoch 1/20\n",
            "1744/1744 [==============================] - 97s 56ms/step - loss: 0.3256 - accuracy: 0.9994 - val_loss: 4.7749 - val_accuracy: 0.0573\n",
            "Epoch 2/20\n",
            "1744/1744 [==============================] - 97s 55ms/step - loss: 0.2424 - accuracy: 1.0000 - val_loss: 4.7993 - val_accuracy: 0.0596\n",
            "Epoch 3/20\n",
            "1744/1744 [==============================] - 100s 57ms/step - loss: 0.1895 - accuracy: 1.0000 - val_loss: 4.8336 - val_accuracy: 0.0642\n",
            "Epoch 4/20\n",
            "1744/1744 [==============================] - 97s 56ms/step - loss: 0.1506 - accuracy: 1.0000 - val_loss: 4.8747 - val_accuracy: 0.0665\n",
            "Epoch 5/20\n",
            "1744/1744 [==============================] - 97s 55ms/step - loss: 0.1260 - accuracy: 1.0000 - val_loss: 4.9027 - val_accuracy: 0.0665\n",
            "Epoch 6/20\n",
            "1744/1744 [==============================] - 97s 55ms/step - loss: 0.1063 - accuracy: 1.0000 - val_loss: 4.9291 - val_accuracy: 0.0665\n",
            "Epoch 7/20\n",
            "1744/1744 [==============================] - 97s 55ms/step - loss: 0.0926 - accuracy: 1.0000 - val_loss: 4.9363 - val_accuracy: 0.0688\n",
            "Epoch 8/20\n",
            "1744/1744 [==============================] - 97s 56ms/step - loss: 0.0821 - accuracy: 1.0000 - val_loss: 4.9559 - val_accuracy: 0.0642\n",
            "Epoch 9/20\n",
            "1744/1744 [==============================] - 97s 55ms/step - loss: 0.0736 - accuracy: 1.0000 - val_loss: 4.9777 - val_accuracy: 0.0619\n",
            "Epoch 10/20\n",
            "1744/1744 [==============================] - 100s 57ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 4.9992 - val_accuracy: 0.0596\n",
            "Epoch 11/20\n",
            "1744/1744 [==============================] - 97s 56ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 5.0225 - val_accuracy: 0.0596\n",
            "Epoch 12/20\n",
            "1744/1744 [==============================] - 97s 56ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 5.0522 - val_accuracy: 0.0596\n",
            "Epoch 13/20\n",
            "1744/1744 [==============================] - 97s 56ms/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 5.0677 - val_accuracy: 0.0596\n",
            "Epoch 14/20\n",
            "1744/1744 [==============================] - 97s 55ms/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 5.0779 - val_accuracy: 0.0596\n",
            "Epoch 15/20\n",
            "1744/1744 [==============================] - 97s 56ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 5.0829 - val_accuracy: 0.0596\n",
            "Epoch 16/20\n",
            "1744/1744 [==============================] - 101s 58ms/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 5.0829 - val_accuracy: 0.0596\n",
            "Epoch 17/20\n",
            "1744/1744 [==============================] - 98s 56ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 5.0784 - val_accuracy: 0.0596\n",
            "Epoch 18/20\n",
            "1744/1744 [==============================] - 97s 56ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 5.0866 - val_accuracy: 0.0596\n",
            "Epoch 19/20\n",
            "1744/1744 [==============================] - 97s 55ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 5.0936 - val_accuracy: 0.0596\n",
            "Epoch 20/20\n",
            "1744/1744 [==============================] - 97s 56ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 5.0969 - val_accuracy: 0.0619\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fc355d72eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvcdNR4yXI4z",
        "colab_type": "text"
      },
      "source": [
        "**Custom built Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQkCtUeUXjRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,(3,3),activation='relu',input_shape=input_shape))\n",
        "model.add(Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(256,(3,3),activation='relu'))\n",
        "model.add(Conv2D(256,(3,3),activation='relu'))\n",
        "model.add(Conv2D(256,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHx68btVZFdl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "1182f8ce-7840-4855-d823-1bcc3e80c671"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 222, 222, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 220, 220, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 110, 110, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 110, 110, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 108, 108, 64)      18496     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 106, 106, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 53, 53, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 53, 53, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 51, 51, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 49, 49, 128)       147584    \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 47, 47, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 23, 23, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 23, 23, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 21, 21, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 19, 19, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 17, 17, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               8389120   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 109)               55917     \n",
            "=================================================================\n",
            "Total params: 10,354,957\n",
            "Trainable params: 10,354,957\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrHuboUcZLoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQiPHwZVZXcv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bdcfb503-fafb-47f9-9838-fdd38756a9c4"
      },
      "source": [
        "model.weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 3, 32) dtype=float32, numpy=\n",
              " array([[[[ 0.04482017, -0.06483161, -0.03653897, -0.02644072,\n",
              "            0.11282937, -0.04154134, -0.09601479,  0.1378886 ,\n",
              "           -0.02752429,  0.05950691,  0.12296759, -0.07441309,\n",
              "            0.009966  , -0.11023463,  0.05360009, -0.03499044,\n",
              "           -0.09472683,  0.08473286,  0.02483855, -0.00056405,\n",
              "            0.01044095,  0.0611151 , -0.06798614, -0.08616297,\n",
              "           -0.01476044,  0.02987106, -0.07433896,  0.035748  ,\n",
              "            0.05886728,  0.13016619, -0.10040332, -0.11743146],\n",
              "          [-0.12111112,  0.10023445,  0.08119571, -0.10250866,\n",
              "           -0.00837891,  0.00016423, -0.03262638, -0.05643583,\n",
              "            0.13478391, -0.07046263,  0.13798277,  0.04076751,\n",
              "           -0.02340117, -0.10515639,  0.12990959,  0.10659358,\n",
              "            0.01609473, -0.03018622,  0.02220702,  0.1253518 ,\n",
              "           -0.11216731,  0.03130692,  0.0300747 , -0.0913261 ,\n",
              "            0.13452931, -0.12525362,  0.06522717, -0.05666403,\n",
              "            0.09920445, -0.0592316 , -0.04977816,  0.05320396],\n",
              "          [-0.10567869, -0.02813885, -0.06704424, -0.08070059,\n",
              "            0.12732671, -0.1059849 ,  0.04561052,  0.07456225,\n",
              "            0.03934984,  0.08073129, -0.11597095, -0.10629553,\n",
              "           -0.05171612,  0.08811876, -0.02203575,  0.07195581,\n",
              "           -0.12177659,  0.01528083,  0.09165651,  0.08250038,\n",
              "           -0.10061862,  0.13255559,  0.08172475,  0.10851644,\n",
              "           -0.09920304, -0.02097841, -0.1322207 , -0.00513178,\n",
              "            0.00674161, -0.03436376, -0.09296504,  0.00269307]],\n",
              " \n",
              "         [[-0.0711508 , -0.11765127, -0.05722025,  0.0965303 ,\n",
              "            0.12956227, -0.10847673, -0.0895807 ,  0.0756797 ,\n",
              "            0.02508281,  0.12526412,  0.02601527,  0.08237611,\n",
              "           -0.1372838 ,  0.06293316,  0.06653455,  0.132625  ,\n",
              "           -0.0542702 ,  0.00709923, -0.08307175,  0.02503154,\n",
              "           -0.06852881, -0.02654322, -0.10216218, -0.03713692,\n",
              "           -0.13783301,  0.0292822 , -0.12650624, -0.09283197,\n",
              "           -0.04775562, -0.01471793,  0.11827035, -0.09406711],\n",
              "          [-0.05987755,  0.02269299,  0.1043008 ,  0.11143912,\n",
              "            0.00925045, -0.0877373 , -0.03679224, -0.06722943,\n",
              "           -0.05547801, -0.0670833 ,  0.0175714 , -0.08642015,\n",
              "            0.09573424,  0.00900841, -0.09713106,  0.05602722,\n",
              "            0.06467706, -0.11497764, -0.0762677 , -0.07305577,\n",
              "           -0.03392833,  0.00340171,  0.07670166, -0.12081958,\n",
              "           -0.10178153, -0.04045383,  0.12160279,  0.01692273,\n",
              "           -0.10691585,  0.03639765, -0.08438452,  0.08678375],\n",
              "          [ 0.11853017,  0.00379755,  0.00309759, -0.13576752,\n",
              "            0.04992369,  0.03661054, -0.07499429,  0.02689435,\n",
              "            0.10538143,  0.08183526,  0.04981998, -0.03702962,\n",
              "           -0.06104857, -0.08859427,  0.13016336, -0.05749869,\n",
              "            0.11493339,  0.08809932, -0.04962274,  0.02230543,\n",
              "           -0.04658224, -0.07936676, -0.05006235, -0.10580774,\n",
              "           -0.08475313, -0.00656009,  0.09037954, -0.01166768,\n",
              "           -0.08412287,  0.01427734, -0.10833786, -0.12126406]],\n",
              " \n",
              "         [[-0.04079219,  0.10552098, -0.12351087,  0.04965793,\n",
              "            0.04563165, -0.12595505,  0.03456786,  0.0306257 ,\n",
              "           -0.03159402,  0.07487722,  0.06543295,  0.08847417,\n",
              "           -0.12538405, -0.12034091, -0.0890784 ,  0.05121492,\n",
              "            0.05603038, -0.06770638,  0.09553817, -0.06498719,\n",
              "            0.0469583 , -0.04718005, -0.07294317, -0.08281973,\n",
              "            0.06698129,  0.00716905,  0.11260147, -0.03094761,\n",
              "            0.02502374, -0.09079933, -0.01717194, -0.11811884],\n",
              "          [ 0.13148238, -0.09736247,  0.03426811,  0.04575698,\n",
              "           -0.07388029,  0.04619636, -0.02680478,  0.12528099,\n",
              "           -0.08703682,  0.01814701, -0.01230679, -0.13098723,\n",
              "            0.04282141, -0.02816777,  0.09139018, -0.02490936,\n",
              "            0.11291717, -0.07511594,  0.10787773,  0.04385202,\n",
              "            0.09123552,  0.03162867, -0.05069476,  0.06752905,\n",
              "            0.10899533,  0.0762893 , -0.04391138,  0.0637144 ,\n",
              "           -0.0793127 ,  0.03116547,  0.02272688, -0.10062858],\n",
              "          [-0.04223599,  0.09561443, -0.01568968,  0.0957576 ,\n",
              "           -0.08249545,  0.09424165, -0.00680634,  0.08747965,\n",
              "            0.06383707,  0.01114252, -0.01525457,  0.06997693,\n",
              "            0.00708304,  0.07227901,  0.11256282,  0.04669704,\n",
              "           -0.03711905, -0.0202729 , -0.10343596, -0.04040892,\n",
              "           -0.05573713, -0.04762374,  0.11261506,  0.11083058,\n",
              "           -0.12425616, -0.05885527,  0.08924893, -0.12908608,\n",
              "           -0.10940172, -0.03975648, -0.06711048,  0.00066049]]],\n",
              " \n",
              " \n",
              "        [[[ 0.04936682, -0.05045129,  0.06544627, -0.10310471,\n",
              "           -0.1320236 ,  0.10309586, -0.07644822,  0.10725644,\n",
              "            0.06428681,  0.03014117, -0.11868287,  0.06214082,\n",
              "           -0.11880623, -0.12074818,  0.09634914, -0.03970909,\n",
              "           -0.0585502 , -0.08348793, -0.11036764,  0.05798967,\n",
              "            0.04876448,  0.02047884, -0.1311301 , -0.11528126,\n",
              "           -0.12267989,  0.04668148,  0.11353548, -0.10801066,\n",
              "           -0.1113819 ,  0.01635876,  0.10249491, -0.00584576],\n",
              "          [-0.11395421, -0.02609561,  0.13370968, -0.04597731,\n",
              "           -0.11151391,  0.02313003,  0.05181256, -0.00897439,\n",
              "            0.04314631,  0.09336677, -0.08450486, -0.0381444 ,\n",
              "           -0.04018836,  0.06427723, -0.11492286,  0.04228841,\n",
              "           -0.1067894 ,  0.11884169,  0.00570196,  0.11468546,\n",
              "            0.01433448, -0.13650863,  0.11137055, -0.01376773,\n",
              "           -0.10166815,  0.06404571,  0.0579361 , -0.00890723,\n",
              "            0.13375075,  0.10928853, -0.06160332, -0.04414191],\n",
              "          [ 0.10514133,  0.00181602,  0.12295635, -0.10230288,\n",
              "           -0.00538759,  0.0602546 ,  0.13644274,  0.03719369,\n",
              "            0.11866583,  0.05943498,  0.11002639, -0.03420858,\n",
              "           -0.05118649,  0.13400479,  0.11002351, -0.0968641 ,\n",
              "           -0.11344095, -0.02843792, -0.01437999, -0.07664072,\n",
              "           -0.12016638, -0.08091378,  0.03735127, -0.01368228,\n",
              "           -0.1194053 ,  0.09783123, -0.02899029,  0.006651  ,\n",
              "            0.10053599,  0.097247  ,  0.13771914,  0.07053594]],\n",
              " \n",
              "         [[ 0.04912752, -0.00874859, -0.10134466,  0.07614079,\n",
              "            0.04185437,  0.00684273,  0.05374846,  0.13762017,\n",
              "            0.09230591, -0.00588813, -0.0021683 ,  0.05162521,\n",
              "           -0.10039058,  0.11873393,  0.01192214,  0.07009166,\n",
              "           -0.11585545,  0.02420595,  0.00381094,  0.05815172,\n",
              "           -0.12103922,  0.06808907, -0.0184499 ,  0.00335659,\n",
              "            0.01929273,  0.12092493,  0.09060864,  0.10444038,\n",
              "           -0.10747678,  0.05965716,  0.08150801, -0.08722593],\n",
              "          [ 0.00583509, -0.06583673,  0.05022846, -0.05774601,\n",
              "            0.06746276,  0.07433248, -0.00248402, -0.01477571,\n",
              "            0.02736653, -0.02186816,  0.11425103, -0.01038258,\n",
              "            0.11986373, -0.03414409,  0.12207927, -0.07809995,\n",
              "           -0.0852083 ,  0.02276637,  0.0502743 , -0.12850073,\n",
              "            0.11886482,  0.11784668, -0.0866775 , -0.13351889,\n",
              "            0.03730105, -0.07053804, -0.13405031, -0.01902889,\n",
              "           -0.01783998, -0.07981327,  0.08116096,  0.09368013],\n",
              "          [-0.08869566, -0.09752364, -0.08587268,  0.13391037,\n",
              "           -0.01416703,  0.10549982,  0.02131096,  0.11829104,\n",
              "           -0.03434583, -0.11712005,  0.00726761, -0.0150305 ,\n",
              "           -0.0335416 ,  0.09972331, -0.02943059,  0.01911132,\n",
              "           -0.0049814 , -0.02873442,  0.02117531,  0.00780267,\n",
              "           -0.02893972,  0.03181146, -0.13165069,  0.09265395,\n",
              "           -0.02370725,  0.0713582 ,  0.03027157, -0.03576498,\n",
              "            0.10288185, -0.02335688,  0.07017051,  0.06700225]],\n",
              " \n",
              "         [[-0.07086436,  0.11118904, -0.10651971, -0.12030821,\n",
              "           -0.11046655,  0.13140689, -0.04152083,  0.11460315,\n",
              "            0.08725981, -0.0914391 , -0.01880527, -0.05210292,\n",
              "           -0.1344817 ,  0.01308413,  0.07785353,  0.08715455,\n",
              "           -0.07041176, -0.08596326,  0.07831788, -0.13709049,\n",
              "           -0.09403257,  0.009831  , -0.04778642,  0.00133176,\n",
              "            0.0364857 , -0.00659862, -0.08599509,  0.06230834,\n",
              "           -0.0802801 ,  0.0457983 ,  0.12047412, -0.02009459],\n",
              "          [-0.11619483, -0.09305944, -0.0694183 ,  0.11932404,\n",
              "            0.1324196 , -0.03075083, -0.09295615,  0.07275206,\n",
              "           -0.07318166,  0.11044069,  0.06188604, -0.06998669,\n",
              "            0.11498643,  0.04412101,  0.02900164, -0.05576141,\n",
              "           -0.04030553,  0.11437537, -0.10397646, -0.0838972 ,\n",
              "            0.0722485 ,  0.08484229, -0.02839774,  0.1100179 ,\n",
              "           -0.1192566 ,  0.07449098,  0.13225712,  0.11791082,\n",
              "            0.10289484, -0.12524042, -0.0343455 , -0.13559532],\n",
              "          [-0.0724387 ,  0.08527842, -0.07697415,  0.1235268 ,\n",
              "            0.10828903, -0.06849933,  0.07207651,  0.04699163,\n",
              "           -0.00670688, -0.01293747,  0.08657961,  0.05464667,\n",
              "           -0.00266519, -0.09850945,  0.12443577,  0.0008889 ,\n",
              "           -0.08269913, -0.07871425, -0.01551864, -0.05450642,\n",
              "           -0.07956554,  0.05035467, -0.09664521, -0.00382467,\n",
              "           -0.01048215, -0.1131203 ,  0.10190128,  0.06416039,\n",
              "            0.03520304, -0.12560122, -0.05377422,  0.02803718]]],\n",
              " \n",
              " \n",
              "        [[[-0.01961375,  0.09606691, -0.11612014,  0.10100195,\n",
              "           -0.08170794, -0.06616551, -0.1143414 , -0.11347027,\n",
              "           -0.10248912,  0.12008481,  0.06603047,  0.12664135,\n",
              "           -0.00660563, -0.12104458, -0.0436661 , -0.00020997,\n",
              "            0.02770776, -0.12507918,  0.1146998 ,  0.1358604 ,\n",
              "           -0.07462   ,  0.1053144 , -0.00023767,  0.07900533,\n",
              "            0.02813539, -0.13727236,  0.04610804,  0.05434963,\n",
              "           -0.09829987,  0.136894  ,  0.09355834,  0.11205368],\n",
              "          [ 0.03030096,  0.06081173,  0.06239133, -0.04723392,\n",
              "           -0.0903103 ,  0.10293087,  0.1281756 ,  0.0267064 ,\n",
              "           -0.01957054, -0.00945081, -0.01095785, -0.09120077,\n",
              "            0.0641007 , -0.01606289, -0.09685676, -0.10621047,\n",
              "           -0.06529304,  0.09469211, -0.00704981, -0.07573919,\n",
              "            0.03715679,  0.01332405, -0.02007419, -0.08817118,\n",
              "            0.05021454,  0.10205349,  0.02286899, -0.05805212,\n",
              "           -0.06589174, -0.13703501,  0.00349693,  0.08853127],\n",
              "          [ 0.11749865, -0.131048  , -0.0928628 ,  0.06652375,\n",
              "           -0.09470303, -0.10610484, -0.10441926,  0.09374632,\n",
              "           -0.0370669 ,  0.13789152, -0.05286085, -0.02821393,\n",
              "            0.02130684,  0.04910311,  0.05085063,  0.05599391,\n",
              "            0.06282212,  0.11753838,  0.04050744, -0.04337279,\n",
              "           -0.01932139, -0.01942511, -0.02927551,  0.13763608,\n",
              "           -0.03340221,  0.03457469,  0.11901771, -0.08204837,\n",
              "            0.04663409, -0.11472609, -0.01692989, -0.10115591]],\n",
              " \n",
              "         [[-0.04857798, -0.00305749,  0.03374314,  0.03323144,\n",
              "           -0.06100468, -0.06182723, -0.02542498, -0.05570785,\n",
              "           -0.00277852, -0.07798636, -0.01914469,  0.03196542,\n",
              "           -0.10662711, -0.12005392,  0.00768876,  0.11540188,\n",
              "           -0.09528973,  0.06591949,  0.00499684,  0.02070946,\n",
              "            0.08833219, -0.06569   , -0.03848339, -0.0438713 ,\n",
              "            0.03693587,  0.10995722,  0.03935763, -0.09948145,\n",
              "           -0.10487844, -0.04064327, -0.02081761, -0.01069357],\n",
              "          [-0.0019151 ,  0.02541731,  0.06906874, -0.1269982 ,\n",
              "           -0.1068862 , -0.0592185 ,  0.13092788,  0.01477729,\n",
              "            0.05699761, -0.00790849, -0.02073465,  0.05655274,\n",
              "            0.13466276, -0.02178188, -0.00908791,  0.08028553,\n",
              "            0.00342171, -0.07494473,  0.06705566,  0.06225401,\n",
              "            0.0079546 , -0.12943783,  0.12271489, -0.09915214,\n",
              "            0.02604425,  0.06935301, -0.0530518 ,  0.02917193,\n",
              "           -0.0521682 ,  0.11653484, -0.09528187,  0.01572134],\n",
              "          [-0.05750297,  0.12126569, -0.1322743 , -0.07663342,\n",
              "           -0.09287435, -0.0048819 , -0.08102082, -0.06322928,\n",
              "            0.1105704 , -0.00678943,  0.0467408 ,  0.03043887,\n",
              "           -0.0563307 , -0.07151592,  0.04276656,  0.06047833,\n",
              "            0.04948471,  0.01078287,  0.07551695,  0.08073093,\n",
              "           -0.09710637, -0.11794393, -0.0152476 ,  0.05730797,\n",
              "           -0.09439389,  0.08999796,  0.07108776,  0.02262908,\n",
              "           -0.11169019,  0.1228206 ,  0.01099257,  0.12195639]],\n",
              " \n",
              "         [[-0.04420229,  0.00096045, -0.04290182, -0.11260448,\n",
              "           -0.02299305, -0.10366669, -0.08912474,  0.07608144,\n",
              "            0.06023994,  0.03769018, -0.10273281,  0.02744968,\n",
              "            0.09164035,  0.04756688, -0.13643469,  0.08074507,\n",
              "            0.00096412,  0.11634122,  0.04279278, -0.07297018,\n",
              "           -0.00120324,  0.09625164,  0.04544672, -0.12431625,\n",
              "            0.03370659,  0.0672881 , -0.06312918, -0.02833713,\n",
              "           -0.00181259, -0.09935845, -0.12258496,  0.01323688],\n",
              "          [-0.00667123, -0.08757133,  0.07489248,  0.0858787 ,\n",
              "            0.01509765, -0.02245469, -0.0376398 , -0.10937326,\n",
              "            0.01682502, -0.07070863,  0.06134811, -0.00761281,\n",
              "           -0.00115141,  0.06502618, -0.07943168, -0.13205539,\n",
              "           -0.08149058, -0.09579252,  0.03718591, -0.04577929,\n",
              "            0.00417177, -0.09790803,  0.12152945,  0.04004607,\n",
              "            0.04246938, -0.09039365,  0.12153088,  0.08923088,\n",
              "            0.00275607,  0.01869498, -0.07009949, -0.11231143],\n",
              "          [ 0.03988573,  0.04888462, -0.10589682,  0.02883488,\n",
              "           -0.0039217 , -0.11578865, -0.09375435, -0.11787377,\n",
              "           -0.01512749, -0.07419065, -0.10174284, -0.10258155,\n",
              "           -0.13475214, -0.08914109, -0.09671661, -0.13649435,\n",
              "           -0.09005433, -0.01148508, -0.10686738, -0.10924019,\n",
              "            0.00840512, -0.08564909,  0.04303858,  0.04098597,\n",
              "            0.10791297, -0.04051395, -0.08574616,  0.13579978,\n",
              "            0.09966233,  0.01487963, -0.13705324, -0.11614623]]]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'conv2d_1/bias:0' shape=(32,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 32, 32) dtype=float32, numpy=\n",
              " array([[[[-0.0240925 ,  0.09708278, -0.01056463, ...,  0.04628579,\n",
              "            0.01100285, -0.06987628],\n",
              "          [-0.10119515,  0.02190433,  0.0538007 , ..., -0.08075964,\n",
              "           -0.01563539, -0.0498003 ],\n",
              "          [ 0.09525143,  0.03228189, -0.05130635, ...,  0.08422424,\n",
              "            0.06711453,  0.06386824],\n",
              "          ...,\n",
              "          [ 0.0644419 ,  0.0344124 ,  0.08912709, ...,  0.04116614,\n",
              "            0.08939591,  0.04758009],\n",
              "          [ 0.05420519, -0.06052706,  0.00928944, ...,  0.06752774,\n",
              "           -0.00778168,  0.09811087],\n",
              "          [ 0.02535455,  0.00571319, -0.06951875, ..., -0.02395053,\n",
              "            0.05578184,  0.10051295]],\n",
              " \n",
              "         [[-0.08767324,  0.09246886, -0.02757866, ..., -0.06831157,\n",
              "           -0.06974989,  0.0534834 ],\n",
              "          [-0.00824567, -0.021022  , -0.05637713, ..., -0.03220492,\n",
              "            0.05315368, -0.09255029],\n",
              "          [-0.07644664,  0.00417504, -0.0161599 , ...,  0.03812154,\n",
              "            0.08033653, -0.03118313],\n",
              "          ...,\n",
              "          [-0.03344466, -0.03273772,  0.05813055, ..., -0.01272252,\n",
              "            0.09718214, -0.07266347],\n",
              "          [ 0.04889409,  0.06956656,  0.02674998, ...,  0.03013395,\n",
              "            0.06491135,  0.06011923],\n",
              "          [-0.01816924,  0.07817468,  0.03775312, ..., -0.09900387,\n",
              "           -0.07863434,  0.01898088]],\n",
              " \n",
              "         [[ 0.03946066,  0.09739384, -0.04564764, ...,  0.05453517,\n",
              "            0.0007466 , -0.09557819],\n",
              "          [-0.0897047 , -0.01606281, -0.00960718, ..., -0.07544748,\n",
              "            0.08346051, -0.06276752],\n",
              "          [ 0.10084859,  0.06744017, -0.09079818, ..., -0.10079134,\n",
              "            0.09597184,  0.02212499],\n",
              "          ...,\n",
              "          [ 0.06909467, -0.07431629, -0.06937638, ...,  0.0635075 ,\n",
              "            0.0011737 , -0.06100103],\n",
              "          [ 0.00286425, -0.09764671,  0.0311511 , ...,  0.00165088,\n",
              "            0.00057217, -0.09564183],\n",
              "          [ 0.07259113, -0.07968248, -0.04228604, ..., -0.07130215,\n",
              "            0.03888954, -0.04821388]]],\n",
              " \n",
              " \n",
              "        [[[ 0.04459405,  0.08122484, -0.00120429, ..., -0.08007404,\n",
              "           -0.07337245, -0.08877598],\n",
              "          [-0.06694096, -0.02690452,  0.00485852, ..., -0.05062905,\n",
              "            0.05092414,  0.09913269],\n",
              "          [ 0.09796198,  0.08655275, -0.04479672, ..., -0.01333179,\n",
              "            0.05997939, -0.02912787],\n",
              "          ...,\n",
              "          [ 0.0865404 ,  0.02364592, -0.0977816 , ...,  0.01274014,\n",
              "           -0.03585297,  0.01613238],\n",
              "          [-0.09725022,  0.00147432,  0.01788164, ..., -0.07861169,\n",
              "            0.05137843, -0.09712248],\n",
              "          [ 0.02304767, -0.09904258,  0.00263337, ..., -0.09066794,\n",
              "            0.07635048,  0.08968918]],\n",
              " \n",
              "         [[-0.09138646, -0.09381743, -0.03869775, ...,  0.04359207,\n",
              "            0.05955766, -0.07145628],\n",
              "          [ 0.05358659, -0.00683939, -0.04970433, ...,  0.04196304,\n",
              "           -0.06681175, -0.08447818],\n",
              "          [-0.07916959,  0.04911993, -0.03760265, ...,  0.06366755,\n",
              "           -0.07574122, -0.05755864],\n",
              "          ...,\n",
              "          [-0.08178125, -0.0276029 , -0.06192716, ..., -0.0292441 ,\n",
              "           -0.03320381, -0.07648329],\n",
              "          [-0.0991286 ,  0.01791897,  0.02683944, ..., -0.04809922,\n",
              "            0.06386009,  0.0966039 ],\n",
              "          [-0.09476957,  0.03881833,  0.07184471, ..., -0.07609444,\n",
              "           -0.07527426, -0.03744441]],\n",
              " \n",
              "         [[-0.00320008,  0.08558619, -0.06707041, ..., -0.01343975,\n",
              "            0.07595883,  0.01809864],\n",
              "          [ 0.02312119, -0.03497913,  0.07983224, ..., -0.03778639,\n",
              "           -0.0738197 , -0.04221779],\n",
              "          [ 0.10010403,  0.02046021,  0.07761183, ...,  0.05303745,\n",
              "           -0.07640773, -0.09843639],\n",
              "          ...,\n",
              "          [-0.09445272, -0.08033947, -0.09306844, ..., -0.07544024,\n",
              "           -0.10117113,  0.07923925],\n",
              "          [ 0.06416565,  0.04627639,  0.0668491 , ...,  0.07568416,\n",
              "            0.03500636,  0.0833941 ],\n",
              "          [-0.07445351,  0.04051213, -0.08573668, ..., -0.08053029,\n",
              "            0.01682939,  0.09723896]]],\n",
              " \n",
              " \n",
              "        [[[-0.09854618, -0.09915902, -0.03882735, ..., -0.03161799,\n",
              "           -0.04742856,  0.07458043],\n",
              "          [ 0.06768237, -0.03203806,  0.01508857, ...,  0.08251634,\n",
              "           -0.08215808, -0.02915021],\n",
              "          [-0.0564011 , -0.04448864,  0.05078712, ...,  0.07907495,\n",
              "           -0.10104754,  0.05255166],\n",
              "          ...,\n",
              "          [-0.06995524,  0.00396646,  0.09821604, ...,  0.05029312,\n",
              "           -0.00859208,  0.02671017],\n",
              "          [-0.03318018, -0.05670393, -0.09470022, ..., -0.07147016,\n",
              "           -0.09105908, -0.09353226],\n",
              "          [-0.04068159, -0.01565237,  0.02646159, ...,  0.01337206,\n",
              "           -0.0783777 , -0.06547216]],\n",
              " \n",
              "         [[ 0.01363788, -0.07427196, -0.01162402, ...,  0.05460575,\n",
              "           -0.04506522, -0.00256825],\n",
              "          [ 0.01055297, -0.08190992, -0.00204805, ...,  0.0986926 ,\n",
              "           -0.02768522, -0.00310905],\n",
              "          [ 0.03672755, -0.0231953 ,  0.01908853, ..., -0.01750559,\n",
              "            0.07604446, -0.03432495],\n",
              "          ...,\n",
              "          [ 0.04888347, -0.01902802,  0.04731998, ..., -0.05398201,\n",
              "           -0.09491535, -0.02511251],\n",
              "          [ 0.02467935, -0.09362551,  0.01326353, ..., -0.02008759,\n",
              "            0.0989607 , -0.05804067],\n",
              "          [ 0.05993457,  0.01938666,  0.07488847, ...,  0.00427165,\n",
              "           -0.03763652, -0.06114078]],\n",
              " \n",
              "         [[ 0.09165247, -0.03410405, -0.08713046, ...,  0.02338916,\n",
              "           -0.09246441,  0.05391331],\n",
              "          [ 0.0232864 , -0.04362127,  0.05090822, ..., -0.055232  ,\n",
              "           -0.01830208, -0.08189866],\n",
              "          [ 0.02293573,  0.07707331, -0.04978361, ...,  0.01734993,\n",
              "           -0.02090135,  0.03156558],\n",
              "          ...,\n",
              "          [ 0.08438362,  0.05015482,  0.03679337, ..., -0.10019657,\n",
              "           -0.06769644, -0.04767377],\n",
              "          [ 0.03546204,  0.05630419,  0.06538126, ..., -0.07135019,\n",
              "           -0.08280866, -0.03536282],\n",
              "          [-0.03039132,  0.0423395 , -0.01348738, ..., -0.07390857,\n",
              "           -0.02474566,  0.05594504]]]], dtype=float32)>,\n",
              " <tf.Variable 'conv2d_2/bias:0' shape=(32,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 32, 64) dtype=float32, numpy=\n",
              " array([[[[-4.99240980e-02, -7.39347339e-02,  2.24011913e-02, ...,\n",
              "            3.73822823e-02, -6.02353811e-02, -2.43260860e-02],\n",
              "          [ 4.38789800e-02,  6.29153922e-02, -4.74314094e-02, ...,\n",
              "           -3.98083553e-02, -5.04653864e-02, -6.84641004e-02],\n",
              "          [-2.25285888e-02, -3.75388861e-02, -1.80459395e-02, ...,\n",
              "            7.97548667e-02,  9.51675326e-03,  7.52331093e-02],\n",
              "          ...,\n",
              "          [-4.52147946e-02, -2.56352052e-02,  7.19004050e-02, ...,\n",
              "            8.16574320e-02, -6.89987168e-02, -2.38882527e-02],\n",
              "          [ 6.32146820e-02, -7.27212280e-02,  6.52799234e-02, ...,\n",
              "           -4.65735793e-02,  4.86593321e-02, -5.06433472e-02],\n",
              "          [ 6.02894053e-02,  3.74284759e-02,  7.15444908e-02, ...,\n",
              "           -4.43417653e-02,  5.63305616e-03, -4.11950760e-02]],\n",
              " \n",
              "         [[ 6.48385361e-02, -5.94855174e-02,  3.36284041e-02, ...,\n",
              "           -4.11521420e-02, -5.33916168e-02, -7.78143406e-02],\n",
              "          [-5.30376658e-02, -3.60405855e-02,  1.31755248e-02, ...,\n",
              "           -8.14888328e-02, -2.55119614e-02, -1.04619637e-02],\n",
              "          [ 5.78900948e-02,  1.08988062e-02,  5.72404042e-02, ...,\n",
              "           -2.94696689e-02,  6.33130223e-03, -2.83915214e-02],\n",
              "          ...,\n",
              "          [ 6.07084110e-02, -6.09357767e-02,  7.73053244e-02, ...,\n",
              "            2.17750669e-02,  3.77688184e-02,  1.47826895e-02],\n",
              "          [ 6.34056702e-02, -3.62436175e-02,  6.38034567e-02, ...,\n",
              "            4.01907936e-02,  8.16036090e-02,  3.15949544e-02],\n",
              "          [ 6.20140210e-02, -5.31809144e-02, -6.56751618e-02, ...,\n",
              "            6.81660995e-02,  4.63010147e-02,  1.26433372e-02]],\n",
              " \n",
              "         [[-2.38452964e-02,  7.29968324e-02,  5.69500029e-04, ...,\n",
              "            2.26736441e-02,  7.07692578e-02,  5.39372936e-02],\n",
              "          [-6.14798069e-02,  8.02907720e-02, -6.53986782e-02, ...,\n",
              "           -2.83016786e-02,  1.76921487e-02,  4.16477323e-02],\n",
              "          [ 2.48016119e-02,  6.13940582e-02,  6.52021244e-02, ...,\n",
              "           -2.31973156e-02,  4.44682017e-02, -4.38970141e-02],\n",
              "          ...,\n",
              "          [-3.81839275e-03,  7.73438886e-02, -5.28844595e-02, ...,\n",
              "           -7.88264722e-02, -6.38659820e-02,  1.18413344e-02],\n",
              "          [-4.51225042e-03, -6.36837110e-02, -6.05126433e-02, ...,\n",
              "            6.19265065e-02, -8.26688856e-02, -1.02660805e-03],\n",
              "          [ 2.49521956e-02, -6.44167289e-02, -5.39158210e-02, ...,\n",
              "           -2.05401182e-02, -3.86261940e-03,  2.58705765e-03]]],\n",
              " \n",
              " \n",
              "        [[[ 6.68332800e-02,  2.87904963e-02,  6.84888735e-02, ...,\n",
              "           -7.41110891e-02, -7.30746835e-02, -5.21507673e-02],\n",
              "          [-4.59892564e-02, -4.60650772e-03,  7.67536983e-02, ...,\n",
              "            5.08419424e-03,  4.26131114e-02,  1.20627508e-02],\n",
              "          [ 6.85819015e-02,  6.69740662e-02, -1.14431158e-02, ...,\n",
              "            1.75496563e-02,  4.18855324e-02,  5.71472421e-02],\n",
              "          ...,\n",
              "          [-7.37114772e-02, -2.25046687e-02,  3.90752330e-02, ...,\n",
              "            5.91058806e-02, -3.47344689e-02,  2.39473358e-02],\n",
              "          [-1.45052671e-02,  2.49519125e-02,  7.94280395e-02, ...,\n",
              "            7.71255717e-02,  8.03391710e-02,  2.82920897e-04],\n",
              "          [ 5.69307804e-03, -8.67694616e-03, -7.85423741e-02, ...,\n",
              "           -3.93367410e-02, -4.76533175e-02,  4.34667543e-02]],\n",
              " \n",
              "         [[-3.46732549e-02, -1.18250474e-02, -6.31189346e-02, ...,\n",
              "           -1.69057027e-02, -7.70736784e-02, -9.26589966e-03],\n",
              "          [ 7.21839443e-02, -8.00955296e-02,  5.63261732e-02, ...,\n",
              "            2.27702484e-02, -3.98007631e-02, -6.59780726e-02],\n",
              "          [-1.25245824e-02, -6.99060410e-02,  5.83008751e-02, ...,\n",
              "           -6.32962435e-02,  8.16034749e-02,  3.07139009e-03],\n",
              "          ...,\n",
              "          [ 6.45638183e-02,  4.08871174e-02, -3.91622782e-02, ...,\n",
              "            6.07529953e-02,  2.39772201e-02, -4.87303734e-03],\n",
              "          [ 5.70830181e-02,  3.59659195e-02, -4.64530587e-02, ...,\n",
              "            4.29173186e-02, -1.94773823e-03, -8.23138803e-02],\n",
              "          [-2.42003053e-03,  1.43776089e-03,  5.56963906e-02, ...,\n",
              "           -4.71959524e-02,  6.32040724e-02, -4.61176261e-02]],\n",
              " \n",
              "         [[ 2.60794535e-02, -2.87073478e-02,  7.64001235e-02, ...,\n",
              "           -7.44437799e-02,  6.78025112e-02, -7.61560425e-02],\n",
              "          [-7.08708167e-02, -2.16409564e-02,  2.75639445e-03, ...,\n",
              "           -5.74325137e-02,  5.21948561e-02,  7.52089173e-03],\n",
              "          [-5.39539270e-02,  1.49627775e-03,  1.46590844e-02, ...,\n",
              "           -4.02733088e-02, -8.18106756e-02, -1.72770992e-02],\n",
              "          ...,\n",
              "          [ 2.72250175e-03,  5.01547530e-02, -6.75365776e-02, ...,\n",
              "            6.27197102e-02,  5.43031767e-02, -2.27092132e-02],\n",
              "          [-4.07143459e-02, -6.17033653e-02, -7.34914169e-02, ...,\n",
              "           -5.57154417e-03, -2.97422819e-02,  6.14063516e-02],\n",
              "          [-8.09885859e-02, -3.44241485e-02,  1.20472685e-02, ...,\n",
              "            7.36198574e-03,  6.59401044e-02, -7.51297921e-02]]],\n",
              " \n",
              " \n",
              "        [[[ 3.75107303e-02,  6.88853115e-03,  5.65171242e-03, ...,\n",
              "           -2.37846598e-02,  6.06423616e-03,  8.09108838e-02],\n",
              "          [ 1.36763826e-02,  6.69134930e-02, -6.53361902e-02, ...,\n",
              "            4.70938161e-02,  4.83325794e-02, -3.27842236e-02],\n",
              "          [-2.40049511e-03,  4.32236865e-02,  3.87630463e-02, ...,\n",
              "            6.59384206e-02,  5.35803810e-02, -2.43366361e-02],\n",
              "          ...,\n",
              "          [ 2.69196928e-04,  6.25625253e-05,  3.12257409e-02, ...,\n",
              "            3.56428623e-02,  7.24021271e-02,  1.87742710e-02],\n",
              "          [ 4.18302044e-02,  6.25544414e-02,  4.78898510e-02, ...,\n",
              "           -3.16564441e-02,  8.26008692e-02,  1.07489228e-02],\n",
              "          [ 4.58429232e-02, -4.66133580e-02, -2.47994810e-03, ...,\n",
              "           -2.26153545e-02,  4.12996039e-02, -5.24767488e-03]],\n",
              " \n",
              "         [[ 2.42566690e-02,  6.93309382e-02,  7.26628676e-02, ...,\n",
              "           -7.07684979e-02, -4.67776060e-02,  7.04512224e-02],\n",
              "          [ 7.62141570e-02, -5.24628386e-02, -6.95026740e-02, ...,\n",
              "           -6.37170076e-02, -2.48238258e-02,  2.22116709e-02],\n",
              "          [ 3.39744315e-02,  8.10647830e-02, -4.62404639e-03, ...,\n",
              "            3.87634262e-02, -2.31922492e-02,  2.73331404e-02],\n",
              "          ...,\n",
              "          [ 2.70290375e-02, -3.50027084e-02,  6.80804253e-03, ...,\n",
              "            7.08057061e-02,  7.31383339e-02,  1.29180551e-02],\n",
              "          [-1.93718672e-02, -8.32218528e-02, -1.67074427e-02, ...,\n",
              "           -7.91162699e-02, -6.50452599e-02,  4.86010313e-03],\n",
              "          [-2.55592689e-02, -5.50768189e-02,  6.80711344e-02, ...,\n",
              "            4.60372791e-02, -4.40662727e-02, -2.38578543e-02]],\n",
              " \n",
              "         [[-7.24246949e-02, -7.86858201e-02,  7.74069875e-03, ...,\n",
              "            3.38946208e-02, -3.28514203e-02,  1.36241689e-02],\n",
              "          [ 5.51841408e-03, -7.91682005e-02,  1.76647082e-02, ...,\n",
              "           -6.19030595e-02,  3.99150625e-02,  2.80306935e-02],\n",
              "          [-1.36116743e-02,  5.12373447e-03,  7.06402138e-02, ...,\n",
              "           -8.28350633e-02, -5.43846935e-03,  1.24683604e-02],\n",
              "          ...,\n",
              "          [ 6.70856610e-02, -7.92559609e-02,  3.85262966e-02, ...,\n",
              "            1.18869320e-02, -1.23291835e-02, -7.38341808e-02],\n",
              "          [ 5.37300929e-02,  3.34372520e-02,  3.29603553e-02, ...,\n",
              "            2.30770335e-02, -2.10805163e-02, -1.89909115e-02],\n",
              "          [ 1.38451234e-02,  1.49297342e-02,  7.14756921e-02, ...,\n",
              "            5.46604395e-03, -3.24145779e-02, -3.19590420e-03]]]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'conv2d_3/bias:0' shape=(64,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'conv2d_4/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
              " array([[[[ 0.06289946,  0.04789511, -0.03214038, ...,  0.0177576 ,\n",
              "            0.05698818,  0.05989048],\n",
              "          [-0.00269499,  0.01032131,  0.03594586, ...,  0.05317418,\n",
              "           -0.05441941,  0.02098739],\n",
              "          [ 0.06217618, -0.05216272,  0.04053   , ..., -0.03221504,\n",
              "            0.04563233,  0.01162126],\n",
              "          ...,\n",
              "          [-0.05949174, -0.06956047, -0.00695198, ...,  0.04045889,\n",
              "           -0.02160092, -0.0122369 ],\n",
              "          [ 0.02549915,  0.03482351,  0.04375807, ...,  0.05346282,\n",
              "           -0.03410906,  0.00657634],\n",
              "          [-0.0546743 ,  0.0070003 , -0.04614507, ..., -0.00530375,\n",
              "           -0.07198071,  0.00335968]],\n",
              " \n",
              "         [[ 0.0447645 , -0.00741939,  0.00564483, ...,  0.01352464,\n",
              "            0.07194908,  0.04409358],\n",
              "          [-0.0539839 , -0.01187231, -0.03069843, ..., -0.06276546,\n",
              "            0.03879059,  0.01123194],\n",
              "          [-0.03332211, -0.05268631,  0.01686736, ...,  0.02322207,\n",
              "           -0.05549486, -0.03097031],\n",
              "          ...,\n",
              "          [-0.01903394, -0.02983872, -0.01862391, ...,  0.03584392,\n",
              "           -0.06124034, -0.01798497],\n",
              "          [ 0.03486921,  0.06099205,  0.06923139, ...,  0.03290363,\n",
              "           -0.04203513, -0.05643331],\n",
              "          [-0.03061538, -0.03336382,  0.00012498, ...,  0.03073137,\n",
              "           -0.03956003, -0.06613085]],\n",
              " \n",
              "         [[-0.02399968, -0.03921566, -0.00241476, ..., -0.04625425,\n",
              "            0.02309397, -0.00395213],\n",
              "          [ 0.0134436 ,  0.06509443, -0.02388182, ..., -0.04544857,\n",
              "            0.00830267,  0.01672491],\n",
              "          [-0.03351176, -0.05145413, -0.03474417, ..., -0.03490698,\n",
              "            0.02964153,  0.02356644],\n",
              "          ...,\n",
              "          [ 0.06274794, -0.01770624, -0.04900423, ...,  0.0437768 ,\n",
              "            0.01160214,  0.04676884],\n",
              "          [-0.03128099,  0.03459147, -0.01050401, ..., -0.06078243,\n",
              "            0.02986754, -0.00699557],\n",
              "          [ 0.00261005,  0.02450539,  0.03377278, ...,  0.06883484,\n",
              "           -0.06173379,  0.01001516]]],\n",
              " \n",
              " \n",
              "        [[[-0.02855937, -0.00841753,  0.01103922, ...,  0.05410224,\n",
              "           -0.02144447,  0.03293896],\n",
              "          [ 0.04090882,  0.05347216,  0.03917318, ..., -0.03208446,\n",
              "           -0.03688277, -0.07051331],\n",
              "          [-0.01752683, -0.02405896,  0.0571779 , ...,  0.02228785,\n",
              "           -0.03395686, -0.00069939],\n",
              "          ...,\n",
              "          [ 0.06212273, -0.00780989,  0.02096945, ..., -0.04738272,\n",
              "           -0.05017981,  0.03932022],\n",
              "          [-0.00932675,  0.05024755,  0.06988366, ..., -0.05214576,\n",
              "           -0.04625808, -0.06273285],\n",
              "          [ 0.02505094,  0.07109803,  0.0074219 , ...,  0.00121899,\n",
              "            0.04913101, -0.05727491]],\n",
              " \n",
              "         [[ 0.05083814, -0.01319014,  0.01222978, ..., -0.01695835,\n",
              "            0.04246064,  0.00796399],\n",
              "          [-0.05015537,  0.01967112,  0.05019281, ..., -0.03322529,\n",
              "           -0.01866307, -0.04688828],\n",
              "          [ 0.04970808,  0.06478965,  0.03405626, ..., -0.05489127,\n",
              "           -0.04950067, -0.05658643],\n",
              "          ...,\n",
              "          [-0.05604243, -0.0337312 ,  0.01594692, ...,  0.05330743,\n",
              "           -0.01841568, -0.00226503],\n",
              "          [-0.03456441, -0.00340753, -0.02749762, ..., -0.00039664,\n",
              "           -0.03952099, -0.0373944 ],\n",
              "          [-0.04475746,  0.05127451,  0.00141987, ..., -0.07015485,\n",
              "            0.01677899, -0.03771786]],\n",
              " \n",
              "         [[-0.00345623, -0.06884219,  0.01598548, ..., -0.04458422,\n",
              "           -0.01741564, -0.03293413],\n",
              "          [-0.04476263,  0.04818515, -0.05392919, ...,  0.05003718,\n",
              "           -0.02810156, -0.0587073 ],\n",
              "          [ 0.0016413 ,  0.03495653,  0.04122236, ..., -0.06397218,\n",
              "           -0.04805141,  0.00582603],\n",
              "          ...,\n",
              "          [ 0.03976079,  0.04875349,  0.05819471, ..., -0.03498903,\n",
              "           -0.04646273,  0.037218  ],\n",
              "          [ 0.03896657,  0.07089025,  0.06733578, ..., -0.01756236,\n",
              "            0.05641371,  0.05416262],\n",
              "          [-0.00553321, -0.03168605, -0.0299491 , ..., -0.01044744,\n",
              "            0.01609425, -0.06950857]]],\n",
              " \n",
              " \n",
              "        [[[-0.06070479,  0.05268843, -0.00365178, ...,  0.0522338 ,\n",
              "           -0.04057357, -0.05105494],\n",
              "          [-0.02574179,  0.018153  ,  0.01051117, ..., -0.06776326,\n",
              "            0.03072096, -0.01958237],\n",
              "          [-0.05779795,  0.02351188, -0.00598124, ...,  0.0320017 ,\n",
              "            0.0124426 ,  0.0702735 ],\n",
              "          ...,\n",
              "          [ 0.06120417,  0.01427452, -0.01657217, ..., -0.00519414,\n",
              "           -0.00265245, -0.03283546],\n",
              "          [ 0.05254747, -0.01617403, -0.01729594, ...,  0.04063811,\n",
              "           -0.00212201, -0.00959916],\n",
              "          [-0.04436016,  0.01030005,  0.07093167, ..., -0.03541183,\n",
              "            0.00411134, -0.0048884 ]],\n",
              " \n",
              "         [[-0.02696334,  0.02826506, -0.00518075, ..., -0.02249789,\n",
              "            0.02772708,  0.05752076],\n",
              "          [ 0.03865562, -0.05497754,  0.06799904, ..., -0.04229118,\n",
              "           -0.03892594,  0.0582006 ],\n",
              "          [ 0.05910441, -0.00415493, -0.04347751, ...,  0.03697491,\n",
              "           -0.06857057, -0.044313  ],\n",
              "          ...,\n",
              "          [ 0.00121365, -0.01917966,  0.05783363, ...,  0.04447348,\n",
              "           -0.01490318, -0.00141163],\n",
              "          [ 0.03606074, -0.07081573,  0.00906228, ...,  0.05483924,\n",
              "           -0.05854572,  0.02911663],\n",
              "          [-0.0088862 ,  0.03475177,  0.05746986, ..., -0.00541788,\n",
              "            0.06513818,  0.00760195]],\n",
              " \n",
              "         [[-0.0442711 , -0.02669399,  0.03594925, ...,  0.05520086,\n",
              "           -0.01345714, -0.07140686],\n",
              "          [-0.05274123,  0.01889068,  0.045523  , ..., -0.0409268 ,\n",
              "            0.0082363 ,  0.01833324],\n",
              "          [ 0.01381789,  0.0702081 ,  0.05509964, ..., -0.06261198,\n",
              "            0.03970773,  0.01646324],\n",
              "          ...,\n",
              "          [-0.03740985, -0.04437604,  0.06925574, ..., -0.07025151,\n",
              "            0.0572484 , -0.0116966 ],\n",
              "          [ 0.05900438, -0.01300284,  0.04233249, ...,  0.05261371,\n",
              "           -0.01922708,  0.00632952],\n",
              "          [-0.06706642, -0.03539152, -0.05972186, ..., -0.00122213,\n",
              "            0.05774181,  0.01530439]]]], dtype=float32)>,\n",
              " <tf.Variable 'conv2d_4/bias:0' shape=(64,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'conv2d_5/kernel:0' shape=(3, 3, 64, 128) dtype=float32, numpy=\n",
              " array([[[[ 2.93730535e-02,  3.55473720e-02, -5.17558083e-02, ...,\n",
              "            2.64286995e-04, -3.13341171e-02, -1.15240850e-02],\n",
              "          [-5.58446012e-02, -2.55341902e-02, -8.13917443e-03, ...,\n",
              "           -1.66793913e-02,  5.54825775e-02, -1.39696859e-02],\n",
              "          [ 2.49574371e-02, -6.32391125e-03,  4.08263914e-02, ...,\n",
              "            4.70329337e-02, -4.90433089e-02, -4.38908413e-02],\n",
              "          ...,\n",
              "          [-5.82883619e-02, -4.72008586e-02, -5.08008897e-02, ...,\n",
              "           -5.17372228e-02,  2.06232071e-05,  1.00697540e-02],\n",
              "          [-9.10218805e-03, -5.40097803e-02,  1.66896023e-02, ...,\n",
              "            4.33546789e-02, -9.13297012e-03, -4.13512997e-02],\n",
              "          [ 3.56295668e-02,  4.52844985e-02, -2.98090745e-02, ...,\n",
              "            1.03371777e-02, -5.16519882e-02,  1.05385520e-02]],\n",
              " \n",
              "         [[ 3.81965823e-02,  9.31235775e-03,  1.85401328e-02, ...,\n",
              "            4.28287424e-02, -5.07899448e-02, -3.16785648e-03],\n",
              "          [ 3.18965130e-02,  4.91009839e-02, -6.05731830e-03, ...,\n",
              "            5.72443716e-02,  3.14902849e-02,  4.51218002e-02],\n",
              "          [ 2.45850720e-02, -3.95593271e-02,  5.80258034e-02, ...,\n",
              "            1.99676566e-02, -1.29040442e-02, -1.18828677e-02],\n",
              "          ...,\n",
              "          [-2.92513743e-02, -4.52161655e-02, -2.89312750e-03, ...,\n",
              "           -1.03540346e-02, -1.94955319e-02, -1.46367848e-02],\n",
              "          [ 4.86222468e-02, -4.31056172e-02,  2.01918557e-03, ...,\n",
              "            4.69658785e-02, -2.59633027e-02,  6.18325546e-03],\n",
              "          [ 1.30753703e-02,  5.59871830e-02, -5.15620187e-02, ...,\n",
              "            7.84925744e-03, -5.16856760e-02,  4.84379791e-02]],\n",
              " \n",
              "         [[ 3.65904905e-02,  5.53266443e-02,  1.41496547e-02, ...,\n",
              "            2.20623575e-02,  2.19774060e-02,  4.79341336e-02],\n",
              "          [ 2.96879746e-02,  2.85329260e-02,  1.85071416e-02, ...,\n",
              "            4.65848707e-02,  4.93447110e-03, -3.87464687e-02],\n",
              "          [ 1.00317113e-02, -4.34748270e-02, -4.62157764e-02, ...,\n",
              "            4.45165820e-02,  2.53917091e-02,  2.77563967e-02],\n",
              "          ...,\n",
              "          [-5.61622903e-02, -4.72133234e-02, -3.80550623e-02, ...,\n",
              "           -1.89443193e-02, -2.20938548e-02, -3.80676091e-02],\n",
              "          [ 4.96082492e-02,  2.13387124e-02,  3.48330475e-02, ...,\n",
              "            1.05564781e-02, -2.85583399e-02,  3.35114487e-02],\n",
              "          [-3.60069126e-02, -3.01690940e-02, -4.33359668e-02, ...,\n",
              "            3.37263457e-02,  4.39684950e-02,  3.30821536e-02]]],\n",
              " \n",
              " \n",
              "        [[[ 2.47255452e-02,  5.04309498e-02,  2.91954614e-02, ...,\n",
              "           -1.55035630e-02, -4.37228754e-02,  1.59733742e-03],\n",
              "          [-2.85710115e-02,  5.72903641e-02, -2.91894320e-02, ...,\n",
              "           -2.70765126e-02,  2.26949565e-02,  3.35824229e-02],\n",
              "          [ 4.77587022e-02, -2.18429416e-02,  2.91306935e-02, ...,\n",
              "            1.07110031e-02, -1.42989941e-02, -1.51913986e-03],\n",
              "          ...,\n",
              "          [-5.32691628e-02, -5.41265421e-02, -3.43268104e-02, ...,\n",
              "           -5.32542281e-02, -5.26449382e-02,  2.90516764e-03],\n",
              "          [ 1.36417933e-02,  6.28372654e-03, -1.66102126e-03, ...,\n",
              "            6.93899021e-03,  4.92429174e-02,  1.06001012e-02],\n",
              "          [ 4.03578542e-02, -4.97523732e-02, -4.16088179e-02, ...,\n",
              "           -1.50431097e-02,  3.58581059e-02,  3.12214456e-02]],\n",
              " \n",
              "         [[ 4.21379246e-02,  2.05655955e-02,  2.90444084e-02, ...,\n",
              "           -2.40322612e-02, -1.51224174e-02,  3.89398970e-02],\n",
              "          [-4.95938733e-02, -2.97434237e-02,  3.39518450e-02, ...,\n",
              "           -2.01995671e-03,  5.03728725e-02,  3.18123586e-02],\n",
              "          [-4.55204360e-02,  3.24783586e-02,  5.46571277e-02, ...,\n",
              "            5.25539331e-02, -2.19552219e-02, -4.14348617e-02],\n",
              "          ...,\n",
              "          [ 2.52302848e-02, -4.03474569e-02,  2.00525187e-02, ...,\n",
              "            4.60399315e-03, -5.65368086e-02,  4.55030836e-02],\n",
              "          [-9.09999758e-03, -5.26572317e-02, -4.41051051e-02, ...,\n",
              "           -2.14893371e-04,  2.80062445e-02, -5.10696024e-02],\n",
              "          [ 2.59803273e-02, -2.39564925e-02,  4.08868007e-02, ...,\n",
              "           -3.06293368e-02, -2.98101436e-02, -2.47114152e-03]],\n",
              " \n",
              "         [[ 5.61295263e-02, -3.32248658e-02,  5.22724204e-02, ...,\n",
              "           -9.11875069e-03,  9.00864974e-03,  1.41321905e-02],\n",
              "          [ 5.77996261e-02,  3.68281566e-02,  4.54150699e-02, ...,\n",
              "            1.62123032e-02,  1.52594484e-02,  1.59032643e-03],\n",
              "          [ 1.29213221e-02, -3.20854820e-02,  2.61179544e-02, ...,\n",
              "           -8.12761486e-04,  1.07846782e-03,  1.34799816e-02],\n",
              "          ...,\n",
              "          [-5.26321009e-02, -1.42387226e-02, -4.30792943e-03, ...,\n",
              "           -2.15404816e-02,  1.18821226e-02,  5.43206446e-02],\n",
              "          [-4.23436016e-02,  2.74896063e-02, -3.64549011e-02, ...,\n",
              "           -2.98681371e-02,  5.48108779e-02,  2.02692635e-02],\n",
              "          [-5.34962229e-02,  5.44105582e-02, -2.39430480e-02, ...,\n",
              "            5.39396219e-02,  4.78788204e-02, -5.08861244e-02]]],\n",
              " \n",
              " \n",
              "        [[[ 3.91169265e-03,  1.04287900e-02, -3.91538441e-03, ...,\n",
              "           -2.91295424e-02, -2.01189667e-02,  1.21030994e-02],\n",
              "          [-1.82830356e-02, -2.34395489e-02, -1.68518983e-02, ...,\n",
              "            4.29551862e-02,  4.56005745e-02,  4.86005954e-02],\n",
              "          [ 1.95425265e-02, -5.31911366e-02, -1.56231485e-02, ...,\n",
              "           -2.89673191e-02,  2.94719823e-02, -3.59703824e-02],\n",
              "          ...,\n",
              "          [ 2.35547386e-02, -5.81948794e-02, -5.13376854e-02, ...,\n",
              "            3.55508365e-02,  1.02773681e-03,  2.89470330e-03],\n",
              "          [-7.89459795e-03,  1.60329677e-02, -3.41403484e-03, ...,\n",
              "            2.45753787e-02,  4.19235714e-02, -6.71190023e-03],\n",
              "          [ 3.99984531e-02,  4.08831611e-03, -5.70544414e-02, ...,\n",
              "            7.55728409e-03, -3.74057516e-02, -2.69423798e-03]],\n",
              " \n",
              "         [[ 1.47796385e-02, -4.12486717e-02,  3.17455269e-02, ...,\n",
              "           -4.32012379e-02, -1.91311166e-02, -2.64287144e-02],\n",
              "          [-1.64134428e-02, -2.94032153e-02,  3.03001292e-02, ...,\n",
              "            1.17580034e-02,  4.66856025e-02,  9.21774283e-03],\n",
              "          [-3.38156894e-03, -1.15796216e-02, -4.29410934e-02, ...,\n",
              "            3.80138718e-02, -3.85284051e-03,  4.26031314e-02],\n",
              "          ...,\n",
              "          [-1.74769349e-02, -3.90990674e-02, -3.88225727e-02, ...,\n",
              "           -4.88511175e-02,  2.83420831e-03,  2.42256857e-02],\n",
              "          [ 4.89604659e-02,  5.08701615e-02,  3.68151478e-02, ...,\n",
              "            2.26303823e-02, -5.29503636e-02, -3.96759063e-03],\n",
              "          [-3.78476754e-02, -4.70601469e-02,  3.67269330e-02, ...,\n",
              "            2.93911360e-02,  2.86003016e-02, -8.02255422e-03]],\n",
              " \n",
              "         [[ 2.12723576e-02,  4.21505049e-03,  1.35702305e-02, ...,\n",
              "           -3.71442847e-02, -1.23865940e-02,  3.81969847e-02],\n",
              "          [ 1.26968697e-03,  1.92188211e-02, -4.95009422e-02, ...,\n",
              "           -4.56458107e-02, -4.79260236e-02,  3.25855128e-02],\n",
              "          [-3.59863006e-02,  2.74843834e-02, -5.72194196e-02, ...,\n",
              "           -2.13270485e-02, -1.51640140e-02, -7.28915632e-03],\n",
              "          ...,\n",
              "          [-1.02983005e-02, -7.75117055e-03,  1.87938102e-02, ...,\n",
              "            4.49287482e-02,  1.57445185e-02, -1.86137185e-02],\n",
              "          [-1.75692923e-02, -7.30486214e-03, -3.55031565e-02, ...,\n",
              "            1.86879300e-02,  5.47980256e-02,  4.11731862e-02],\n",
              "          [ 3.44450586e-02, -1.09623820e-02, -4.06879932e-03, ...,\n",
              "           -1.30035803e-02, -1.84257589e-02,  1.78917311e-02]]]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'conv2d_5/bias:0' shape=(128,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'conv2d_6/kernel:0' shape=(3, 3, 128, 128) dtype=float32, numpy=\n",
              " array([[[[ 4.23466787e-02,  3.42611223e-02,  2.59487405e-02, ...,\n",
              "           -6.73879683e-03,  2.08951607e-02,  3.81042063e-02],\n",
              "          [-1.96522176e-02,  4.02956828e-02, -4.60924096e-02, ...,\n",
              "            3.11323479e-02, -5.06573543e-03, -1.21122040e-02],\n",
              "          [-4.69978936e-02, -1.14645921e-02,  3.49781811e-02, ...,\n",
              "           -4.51596938e-02, -3.99642363e-02,  4.39784527e-02],\n",
              "          ...,\n",
              "          [ 1.19840130e-02, -4.30840328e-02, -2.77065560e-02, ...,\n",
              "            1.86612010e-02,  3.77274454e-02,  4.20005247e-02],\n",
              "          [ 3.12315896e-02, -1.21386535e-02,  4.23300490e-02, ...,\n",
              "           -1.30165704e-02,  2.99179256e-02,  1.48977339e-02],\n",
              "          [-1.08767562e-02,  1.68716013e-02, -4.80306447e-02, ...,\n",
              "           -1.94737315e-02,  5.02890646e-02, -4.20194454e-02]],\n",
              " \n",
              "         [[-3.12709510e-02,  4.04514447e-02, -1.49246342e-02, ...,\n",
              "            3.24112549e-02,  4.49522510e-02,  4.09866422e-02],\n",
              "          [ 4.72697839e-02,  4.08594906e-02, -9.40185413e-03, ...,\n",
              "            4.74531054e-02,  2.04760209e-03, -2.22113598e-02],\n",
              "          [ 3.16456482e-02, -4.17388529e-02,  3.31581756e-03, ...,\n",
              "            1.62825286e-02, -3.53710353e-03, -5.05159721e-02],\n",
              "          ...,\n",
              "          [ 4.83781174e-02,  4.34054583e-02, -2.58224495e-02, ...,\n",
              "           -2.70232558e-05, -3.73140052e-02,  3.27449143e-02],\n",
              "          [ 4.72685099e-02, -2.53443457e-02, -3.41360867e-02, ...,\n",
              "            3.69962826e-02,  3.59315798e-02, -1.24918446e-02],\n",
              "          [-1.84665807e-02,  3.73438001e-02, -3.08749471e-02, ...,\n",
              "            4.47798371e-02, -1.19332224e-04, -3.14472839e-02]],\n",
              " \n",
              "         [[-4.37058546e-02,  3.27717066e-02, -1.83943585e-02, ...,\n",
              "            4.98618111e-02, -2.91190911e-02, -3.56783718e-03],\n",
              "          [-9.90724936e-03, -2.21095476e-02,  4.50467467e-02, ...,\n",
              "           -3.99804078e-02, -4.90501225e-02, -2.01342031e-02],\n",
              "          [-3.77332084e-02, -3.11827902e-02, -2.96524204e-02, ...,\n",
              "           -4.64469492e-02,  3.02689597e-02, -4.81566936e-02],\n",
              "          ...,\n",
              "          [ 1.77016109e-02,  3.60373333e-02,  1.87071413e-02, ...,\n",
              "           -1.83238871e-02,  1.48861110e-02,  3.44649553e-02],\n",
              "          [ 2.53602117e-02,  2.99134851e-02, -2.93552708e-02, ...,\n",
              "           -1.30072981e-02, -4.10913751e-02,  8.15122202e-03],\n",
              "          [-4.18760963e-02, -1.24443322e-02,  2.17744634e-02, ...,\n",
              "           -1.30159780e-03,  1.45567730e-02,  4.28261980e-02]]],\n",
              " \n",
              " \n",
              "        [[[-2.15349365e-02,  2.28726342e-02, -1.67291686e-02, ...,\n",
              "            3.20040211e-02, -4.11193222e-02,  4.65146452e-02],\n",
              "          [-3.93221863e-02,  5.13272360e-03, -1.58617646e-02, ...,\n",
              "            3.67309824e-02, -1.25092305e-02,  1.19763836e-02],\n",
              "          [-2.94810161e-03,  2.24067643e-03,  3.66617218e-02, ...,\n",
              "            3.52166891e-02,  3.68974879e-02,  5.02698720e-02],\n",
              "          ...,\n",
              "          [ 4.53623906e-02, -2.08426733e-02, -3.41796428e-02, ...,\n",
              "           -4.07905653e-02, -3.20484638e-02, -4.40992154e-02],\n",
              "          [ 4.30378243e-02, -3.37953046e-02,  3.28682512e-02, ...,\n",
              "           -3.07859592e-02,  5.68079948e-03, -4.62511368e-02],\n",
              "          [ 2.41564959e-02, -3.27537581e-02, -3.96586098e-02, ...,\n",
              "           -2.33868137e-03, -1.43144690e-02, -2.30408143e-02]],\n",
              " \n",
              "         [[-4.40439656e-02, -4.66673747e-02, -8.51732120e-03, ...,\n",
              "           -3.43044251e-02,  6.06201962e-03, -9.46070626e-03],\n",
              "          [-2.90850475e-02, -3.05865221e-02, -3.91165093e-02, ...,\n",
              "            2.54215449e-02,  1.58066228e-02,  1.56186819e-02],\n",
              "          [ 1.70866549e-02, -3.79669555e-02, -7.68226758e-03, ...,\n",
              "            1.92218274e-02,  3.24627161e-02,  3.66067663e-02],\n",
              "          ...,\n",
              "          [ 4.10063416e-02,  4.04042229e-02,  2.24198326e-02, ...,\n",
              "            1.49163231e-03,  1.75781623e-02,  2.15696692e-02],\n",
              "          [ 3.64451110e-03,  2.04498097e-02, -4.27610315e-02, ...,\n",
              "            3.12742591e-02, -5.54651767e-03, -4.70330194e-02],\n",
              "          [-3.65898386e-02,  3.83100361e-02, -5.00702672e-02, ...,\n",
              "           -3.71993184e-02,  1.38022602e-02, -1.11319795e-02]],\n",
              " \n",
              "         [[-3.09442244e-02,  1.02877133e-02,  1.19685382e-03, ...,\n",
              "            5.56841493e-03, -4.77489233e-02,  6.38536364e-03],\n",
              "          [ 5.07908911e-02,  3.73592228e-03, -1.59221105e-02, ...,\n",
              "            3.79492790e-02,  2.28070319e-02,  1.03368610e-03],\n",
              "          [ 2.24631950e-02, -4.83012572e-02,  4.36950475e-02, ...,\n",
              "           -2.11416576e-02,  1.17633864e-02,  4.00955305e-02],\n",
              "          ...,\n",
              "          [-2.67085899e-02,  2.13131830e-02, -2.25803033e-02, ...,\n",
              "            8.81159678e-03, -4.91372235e-02, -2.35503223e-02],\n",
              "          [ 4.41273302e-03, -2.17668582e-02, -1.49371177e-02, ...,\n",
              "            1.30136162e-02,  3.07787359e-02, -1.95149407e-02],\n",
              "          [-2.31375396e-02, -3.23225111e-02, -5.00885062e-02, ...,\n",
              "           -2.38049105e-02,  2.55805999e-02,  9.49372351e-03]]],\n",
              " \n",
              " \n",
              "        [[[ 1.07057765e-02, -2.09968742e-02,  1.09036081e-02, ...,\n",
              "           -3.99771705e-02, -1.78346373e-02, -2.79863551e-02],\n",
              "          [ 1.57071501e-02,  3.93347517e-02, -3.39967757e-02, ...,\n",
              "           -4.52759713e-02,  4.35263962e-02,  1.87613070e-02],\n",
              "          [ 2.61915252e-02,  2.37467661e-02, -2.26978958e-02, ...,\n",
              "           -4.70074713e-02,  2.63294503e-02, -1.77803636e-03],\n",
              "          ...,\n",
              "          [ 1.45368278e-02, -3.57237831e-02,  4.38888669e-02, ...,\n",
              "           -4.90541011e-02,  8.41761380e-03,  1.10660121e-03],\n",
              "          [ 1.92406252e-02,  1.33448020e-02, -4.98998947e-02, ...,\n",
              "           -2.76586190e-02, -3.36337313e-02, -2.19604205e-02],\n",
              "          [-4.89759669e-02, -1.42719708e-02,  3.81824151e-02, ...,\n",
              "           -3.52922454e-02,  8.68105888e-03,  1.50141940e-02]],\n",
              " \n",
              "         [[ 4.00135219e-02,  9.66432691e-03,  2.69734636e-02, ...,\n",
              "           -2.98154540e-02,  3.87519449e-02,  7.03128427e-03],\n",
              "          [ 3.52597237e-03,  4.06024829e-02,  4.82355356e-02, ...,\n",
              "           -3.66851911e-02,  2.28510275e-02,  4.09233421e-02],\n",
              "          [-5.16900793e-03,  2.22859532e-03, -2.28664037e-02, ...,\n",
              "           -6.68797642e-03, -4.43773717e-03, -2.01559085e-02],\n",
              "          ...,\n",
              "          [ 3.44485492e-02,  1.70028359e-02, -1.49784982e-03, ...,\n",
              "            4.89533246e-02,  3.25606763e-02, -2.65497658e-02],\n",
              "          [-1.78689025e-02,  5.34470752e-03,  1.99760869e-02, ...,\n",
              "            1.90757588e-02, -2.61163861e-02,  4.45954874e-02],\n",
              "          [ 3.52975726e-02,  1.61103830e-02, -3.19919027e-02, ...,\n",
              "            1.41616687e-02, -2.69037113e-03,  1.55859962e-02]],\n",
              " \n",
              "         [[-1.20306276e-02, -4.88721356e-02, -1.20022781e-02, ...,\n",
              "            1.20428801e-02, -1.87525824e-02, -2.56874114e-02],\n",
              "          [ 2.20822543e-02,  4.47958633e-02,  1.45453438e-02, ...,\n",
              "           -3.71617861e-02,  2.95815468e-02, -4.64655869e-02],\n",
              "          [ 2.45995820e-03,  1.29274279e-03,  2.27879509e-02, ...,\n",
              "           -1.85410269e-02, -8.55211169e-04,  2.59846076e-02],\n",
              "          ...,\n",
              "          [ 4.09499928e-03, -2.74937227e-02,  3.27009782e-02, ...,\n",
              "            4.32345271e-02, -1.96275450e-02,  1.31886601e-02],\n",
              "          [-2.91383136e-02, -2.47439407e-02,  4.16776836e-02, ...,\n",
              "           -2.54498180e-02, -9.04715806e-03, -4.22330685e-02],\n",
              "          [-9.75622237e-03, -1.34886876e-02, -3.60544398e-03, ...,\n",
              "            7.13394955e-03,  9.51696560e-03, -8.67848098e-03]]]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'conv2d_6/bias:0' shape=(128,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'conv2d_7/kernel:0' shape=(3, 3, 128, 128) dtype=float32, numpy=\n",
              " array([[[[-0.0453443 ,  0.04902878,  0.03904342, ...,  0.00708801,\n",
              "            0.03277586,  0.03546184],\n",
              "          [ 0.0361724 , -0.02696109,  0.00305869, ..., -0.03813407,\n",
              "           -0.03732987, -0.03970402],\n",
              "          [-0.03017661, -0.0070911 ,  0.01848824, ..., -0.00290545,\n",
              "            0.04142122, -0.00670335],\n",
              "          ...,\n",
              "          [-0.03118672,  0.02388545, -0.01776598, ...,  0.04753861,\n",
              "           -0.03744406, -0.00595579],\n",
              "          [ 0.02081291,  0.03879695,  0.02284354, ...,  0.04499583,\n",
              "            0.04822311, -0.03402641],\n",
              "          [ 0.00835971,  0.02755933,  0.04440784, ...,  0.02898104,\n",
              "            0.01331624, -0.00557549]],\n",
              " \n",
              "         [[-0.0417431 , -0.02734615, -0.01655381, ...,  0.04607056,\n",
              "           -0.02801872,  0.02488533],\n",
              "          [-0.02518592, -0.00738496, -0.00823604, ...,  0.02118032,\n",
              "            0.03759896,  0.013436  ],\n",
              "          [ 0.01811294,  0.02870487,  0.00489939, ..., -0.01160781,\n",
              "            0.01307531,  0.00524822],\n",
              "          ...,\n",
              "          [ 0.01786932,  0.0329037 , -0.04420834, ..., -0.0137267 ,\n",
              "            0.04403147,  0.01929986],\n",
              "          [-0.03056528, -0.03463768, -0.03581746, ...,  0.03627525,\n",
              "            0.01179557,  0.02293776],\n",
              "          [-0.02290562,  0.00508618, -0.01688876, ...,  0.03435832,\n",
              "           -0.04013085, -0.04649238]],\n",
              " \n",
              "         [[-0.04714267,  0.02028778, -0.05054999, ...,  0.01595122,\n",
              "            0.00061785, -0.04909402],\n",
              "          [-0.00659893,  0.01080848, -0.02396018, ...,  0.04506318,\n",
              "           -0.00990344, -0.01389853],\n",
              "          [ 0.00856281, -0.01182194, -0.04316829, ..., -0.02939581,\n",
              "            0.04154633, -0.03679743],\n",
              "          ...,\n",
              "          [-0.03170988,  0.01838813, -0.04569464, ..., -0.02270269,\n",
              "           -0.00186004, -0.01986838],\n",
              "          [ 0.02898365,  0.02039978,  0.01118853, ...,  0.0083744 ,\n",
              "            0.00822753,  0.04143488],\n",
              "          [ 0.02742518,  0.03534058,  0.03962114, ..., -0.04227018,\n",
              "            0.0475205 , -0.0248553 ]]],\n",
              " \n",
              " \n",
              "        [[[-0.01675694,  0.02003399,  0.05008377, ...,  0.00431941,\n",
              "           -0.02275402,  0.00778382],\n",
              "          [ 0.0310557 , -0.01250453, -0.04435899, ...,  0.033201  ,\n",
              "            0.02239345, -0.0102386 ],\n",
              "          [ 0.00122474,  0.0435368 ,  0.02614295, ...,  0.03939155,\n",
              "           -0.04994143,  0.0164231 ],\n",
              "          ...,\n",
              "          [-0.01926365, -0.02903894, -0.00796331, ...,  0.02188057,\n",
              "           -0.03812923,  0.02573228],\n",
              "          [ 0.00719908, -0.01589356, -0.04944499, ..., -0.0252308 ,\n",
              "           -0.05004726,  0.04604445],\n",
              "          [-0.03080717,  0.01352232,  0.03776456, ..., -0.03668504,\n",
              "            0.03605052, -0.0173554 ]],\n",
              " \n",
              "         [[ 0.0048411 , -0.01849857,  0.00984634, ..., -0.03497442,\n",
              "           -0.01331699, -0.0470915 ],\n",
              "          [ 0.03514988,  0.01390399,  0.04717349, ..., -0.03939566,\n",
              "           -0.04940419,  0.03389677],\n",
              "          [ 0.04415356, -0.01779364, -0.00292862, ...,  0.04678551,\n",
              "           -0.00427576,  0.00458708],\n",
              "          ...,\n",
              "          [ 0.02425396,  0.02364474, -0.04602578, ...,  0.0356657 ,\n",
              "            0.02500342, -0.04209608],\n",
              "          [-0.02138379, -0.00442531,  0.00914157, ..., -0.01378375,\n",
              "            0.01191331,  0.00642947],\n",
              "          [ 0.03991433,  0.02020431,  0.00558176, ..., -0.02159897,\n",
              "           -0.01227405, -0.04583552]],\n",
              " \n",
              "         [[ 0.03574414, -0.01203564,  0.00386961, ..., -0.00966047,\n",
              "           -0.01251163,  0.03013603],\n",
              "          [-0.04070575,  0.05049296, -0.0064621 , ..., -0.02464243,\n",
              "           -0.01970445, -0.0225366 ],\n",
              "          [ 0.00384463,  0.011103  , -0.02685564, ..., -0.02233749,\n",
              "           -0.00268543, -0.00533143],\n",
              "          ...,\n",
              "          [ 0.02838154, -0.00227938, -0.01556941, ..., -0.0045957 ,\n",
              "           -0.03838827,  0.0239535 ],\n",
              "          [ 0.01082147, -0.00871178,  0.01307958, ...,  0.01815337,\n",
              "           -0.03567804, -0.0312971 ],\n",
              "          [ 0.04213888, -0.04351706,  0.00867189, ...,  0.04368263,\n",
              "           -0.03189728, -0.00629757]]],\n",
              " \n",
              " \n",
              "        [[[ 0.0483821 , -0.00764195,  0.02682595, ..., -0.01425883,\n",
              "           -0.02272641, -0.0402471 ],\n",
              "          [ 0.034199  ,  0.01423932, -0.0416109 , ..., -0.00346655,\n",
              "           -0.00809463, -0.01037726],\n",
              "          [ 0.0012592 ,  0.03033568, -0.01607263, ..., -0.00718685,\n",
              "           -0.04007504,  0.03891366],\n",
              "          ...,\n",
              "          [ 0.01505669, -0.03247131,  0.00661619, ..., -0.04914287,\n",
              "            0.04562893,  0.0195164 ],\n",
              "          [ 0.00499896,  0.00197542,  0.01599329, ..., -0.00799285,\n",
              "            0.00774255,  0.04770387],\n",
              "          [-0.01110043, -0.01036281,  0.01012801, ...,  0.04405046,\n",
              "            0.02505708, -0.04648307]],\n",
              " \n",
              "         [[-0.02158098, -0.01949671,  0.04911799, ...,  0.01439545,\n",
              "            0.00969231,  0.03251307],\n",
              "          [ 0.00945929,  0.04611804, -0.01382162, ..., -0.0060591 ,\n",
              "           -0.04236872,  0.04353628],\n",
              "          [-0.0156059 , -0.01623293,  0.01929238, ..., -0.04308433,\n",
              "            0.02855182,  0.05062766],\n",
              "          ...,\n",
              "          [ 0.0097926 ,  0.005417  ,  0.03413547, ..., -0.01401028,\n",
              "            0.02507698,  0.02417284],\n",
              "          [ 0.00874878,  0.02548127, -0.00068538, ...,  0.03685724,\n",
              "            0.03164186,  0.01833108],\n",
              "          [ 0.04617705,  0.04281432, -0.01536391, ..., -0.02148878,\n",
              "           -0.00189166,  0.00782321]],\n",
              " \n",
              "         [[-0.03725226, -0.02007499,  0.03768598, ...,  0.02631803,\n",
              "            0.00189297, -0.01292261],\n",
              "          [-0.03655743,  0.00405346,  0.04844379, ..., -0.00995127,\n",
              "           -0.01481149,  0.0311253 ],\n",
              "          [ 0.01013265,  0.04531945, -0.03458448, ...,  0.02488538,\n",
              "           -0.04792473,  0.04020151],\n",
              "          ...,\n",
              "          [-0.01289062, -0.03243028,  0.03258655, ...,  0.00182859,\n",
              "           -0.04418653, -0.01674317],\n",
              "          [ 0.02352516, -0.04240683, -0.02389161, ...,  0.01854991,\n",
              "            0.02469221, -0.01116092],\n",
              "          [-0.0264144 , -0.03977069, -0.00795176, ...,  0.04509183,\n",
              "           -0.04528648, -0.01566596]]]], dtype=float32)>,\n",
              " <tf.Variable 'conv2d_7/bias:0' shape=(128,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'conv2d_8/kernel:0' shape=(3, 3, 128, 256) dtype=float32, numpy=\n",
              " array([[[[ 0.01943108, -0.01717305, -0.02259471, ...,  0.01651034,\n",
              "           -0.00173761, -0.02668124],\n",
              "          [-0.03033806, -0.03045835, -0.03454147, ..., -0.02023005,\n",
              "            0.00120057,  0.01627854],\n",
              "          [-0.03270344, -0.01164486, -0.02432148, ...,  0.03484519,\n",
              "            0.0256328 ,  0.02882135],\n",
              "          ...,\n",
              "          [ 0.03082267,  0.0368924 ,  0.01069273, ..., -0.02076518,\n",
              "           -0.01502543, -0.03231288],\n",
              "          [-0.01830152, -0.02347868, -0.00382227, ..., -0.01366843,\n",
              "            0.01069295, -0.01350839],\n",
              "          [ 0.01299198,  0.04118464,  0.0332479 , ...,  0.01795984,\n",
              "           -0.02929248,  0.00298734]],\n",
              " \n",
              "         [[ 0.02906834,  0.01695058, -0.03582903, ...,  0.01072486,\n",
              "            0.03161583,  0.01246454],\n",
              "          [ 0.00092263, -0.02287122, -0.02790606, ...,  0.01793427,\n",
              "           -0.0362047 ,  0.02051635],\n",
              "          [-0.02244966, -0.03699838, -0.03910754, ...,  0.01447526,\n",
              "           -0.00976858,  0.03800483],\n",
              "          ...,\n",
              "          [ 0.03376106, -0.03380774, -0.01671485, ...,  0.03923861,\n",
              "            0.02655976,  0.0169858 ],\n",
              "          [-0.00953313, -0.0138286 ,  0.00997592, ...,  0.00521721,\n",
              "            0.02265293,  0.01591855],\n",
              "          [ 0.01828177,  0.02958364,  0.01962413, ...,  0.01735508,\n",
              "           -0.01860916, -0.00385141]],\n",
              " \n",
              "         [[-0.01412618,  0.02365853,  0.03255804, ..., -0.00091119,\n",
              "            0.02439812, -0.00950943],\n",
              "          [-0.01541104, -0.00351487,  0.04147521, ..., -0.0144656 ,\n",
              "           -0.03404251, -0.03383449],\n",
              "          [ 0.00102854, -0.01610531,  0.02929754, ..., -0.03074392,\n",
              "            0.02502798, -0.03220497],\n",
              "          ...,\n",
              "          [-0.02663023,  0.00898573,  0.01990698, ...,  0.03886027,\n",
              "           -0.02839683,  0.01461774],\n",
              "          [-0.00165556, -0.01158599, -0.01863918, ..., -0.02220588,\n",
              "            0.01106034,  0.02355172],\n",
              "          [-0.02216384,  0.02697473, -0.03342283, ...,  0.01728543,\n",
              "           -0.00549619,  0.03506466]]],\n",
              " \n",
              " \n",
              "        [[[-0.02901906, -0.02548328, -0.02026428, ..., -0.03319685,\n",
              "            0.02880247,  0.01894327],\n",
              "          [-0.02555436,  0.00329434,  0.03343795, ..., -0.00902642,\n",
              "            0.0142605 , -0.01074195],\n",
              "          [-0.02601466, -0.00538586, -0.03266272, ...,  0.03057181,\n",
              "           -0.00725866, -0.00146743],\n",
              "          ...,\n",
              "          [ 0.03076033,  0.01843363,  0.01505456, ...,  0.03733448,\n",
              "           -0.0068245 , -0.0286722 ],\n",
              "          [ 0.01511604,  0.01460393,  0.0352272 , ..., -0.00609823,\n",
              "            0.04059558, -0.02690085],\n",
              "          [-0.0379182 ,  0.0195432 , -0.01782307, ...,  0.01567356,\n",
              "            0.01594093, -0.02909372]],\n",
              " \n",
              "         [[-0.03122147, -0.01168684,  0.03845502, ...,  0.00266982,\n",
              "            0.02702894,  0.0001426 ],\n",
              "          [ 0.0272165 ,  0.01788269,  0.00701337, ...,  0.02791233,\n",
              "           -0.02552555, -0.02775951],\n",
              "          [-0.03830128,  0.02911244, -0.04047447, ..., -0.01321045,\n",
              "           -0.00560611, -0.03239235],\n",
              "          ...,\n",
              "          [-0.01347183,  0.02417295,  0.01260449, ...,  0.02514378,\n",
              "           -0.02950699, -0.02466112],\n",
              "          [-0.00221066, -0.00940743, -0.02565713, ...,  0.04166119,\n",
              "            0.0286325 , -0.03570879],\n",
              "          [ 0.01318519,  0.04124381,  0.03920175, ..., -0.03953741,\n",
              "            0.03142624,  0.00278184]],\n",
              " \n",
              "         [[-0.03728496, -0.03185796, -0.02011116, ..., -0.04065574,\n",
              "            0.02468789,  0.03250156],\n",
              "          [-0.03541293,  0.03781251,  0.02182759, ..., -0.01582913,\n",
              "           -0.00543631,  0.01375516],\n",
              "          [-0.03990858, -0.00525269, -0.0068765 , ..., -0.04016609,\n",
              "           -0.03856863,  0.00096183],\n",
              "          ...,\n",
              "          [ 0.02281022, -0.04162564,  0.01901761, ..., -0.02694478,\n",
              "           -0.02479305, -0.01900468],\n",
              "          [-0.0095901 , -0.03065262, -0.03753779, ..., -0.01786545,\n",
              "            0.00083659, -0.03110017],\n",
              "          [-0.03827105,  0.01977902,  0.00937702, ...,  0.0345798 ,\n",
              "            0.03061111,  0.00104345]]],\n",
              " \n",
              " \n",
              "        [[[-0.01667718, -0.04054351,  0.03075625, ...,  0.022128  ,\n",
              "            0.02597521, -0.02832764],\n",
              "          [ 0.00652745,  0.02934666, -0.0149332 , ...,  0.03977493,\n",
              "           -0.02432756, -0.0152978 ],\n",
              "          [-0.01335254, -0.0061498 ,  0.03916142, ..., -0.00785984,\n",
              "            0.02936138,  0.02171395],\n",
              "          ...,\n",
              "          [ 0.04144119,  0.03185451,  0.03442348, ..., -0.01442998,\n",
              "            0.02150236, -0.03193644],\n",
              "          [-0.00439532,  0.04083088, -0.00425412, ...,  0.02888841,\n",
              "            0.0179768 , -0.02108259],\n",
              "          [ 0.00042719,  0.02879003, -0.03332605, ..., -0.01537153,\n",
              "            0.00624795, -0.0375698 ]],\n",
              " \n",
              "         [[-0.03080084, -0.01337039,  0.02596182, ...,  0.03858168,\n",
              "            0.0262786 , -0.01965431],\n",
              "          [ 0.00404362,  0.01263022,  0.01645927, ..., -0.04035547,\n",
              "           -0.01761334,  0.00449172],\n",
              "          [ 0.03796942, -0.02976049, -0.01967418, ...,  0.02752017,\n",
              "           -0.0185087 ,  0.03922678],\n",
              "          ...,\n",
              "          [-0.00185757,  0.02871308, -0.01982645, ...,  0.01598234,\n",
              "           -0.03501382,  0.01794544],\n",
              "          [-0.01575192, -0.01280795,  0.03823365, ...,  0.03814462,\n",
              "           -0.01256561, -0.03232558],\n",
              "          [ 0.0362089 , -0.02042444, -0.02560579, ..., -0.00089146,\n",
              "           -0.03998343, -0.01713008]],\n",
              " \n",
              "         [[-0.02806471,  0.00957445,  0.00420603, ...,  0.00451585,\n",
              "            0.01952603,  0.02956663],\n",
              "          [-0.01582067, -0.00497868,  0.00458046, ...,  0.02508171,\n",
              "           -0.00975392,  0.04096217],\n",
              "          [-0.02933207, -0.01960523, -0.02820384, ..., -0.02864869,\n",
              "           -0.01234537, -0.00594068],\n",
              "          ...,\n",
              "          [ 0.02346357,  0.02418679,  0.02614415, ..., -0.00184072,\n",
              "            0.0220382 , -0.00555902],\n",
              "          [-0.02092394,  0.02217953,  0.01044855, ...,  0.03649696,\n",
              "            0.01292518, -0.01402856],\n",
              "          [-0.02914496, -0.01278491,  0.04033269, ..., -0.01993095,\n",
              "           -0.0158711 , -0.00275541]]]], dtype=float32)>,\n",
              " <tf.Variable 'conv2d_8/bias:0' shape=(256,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.], dtype=float32)>,\n",
              " <tf.Variable 'conv2d_9/kernel:0' shape=(3, 3, 256, 256) dtype=float32, numpy=\n",
              " array([[[[-8.42321105e-03, -1.27349403e-02,  8.49288702e-03, ...,\n",
              "            3.20058241e-02,  1.99641660e-02, -9.90287215e-03],\n",
              "          [-2.50172839e-02, -1.63052380e-02,  9.81504470e-03, ...,\n",
              "           -7.38746487e-03,  3.68145108e-03,  1.82685889e-02],\n",
              "          [-1.32401027e-02,  3.75655666e-03,  3.49393860e-02, ...,\n",
              "           -2.45652720e-02, -3.12286224e-02, -6.59698620e-03],\n",
              "          ...,\n",
              "          [-3.57328318e-02, -2.31045708e-02, -1.87288243e-02, ...,\n",
              "           -2.72458456e-02,  2.56917477e-02,  1.89807191e-02],\n",
              "          [ 3.29980627e-02,  2.26581767e-02,  3.17731202e-02, ...,\n",
              "            3.12209725e-02, -6.03519753e-03, -2.91482937e-02],\n",
              "          [ 6.09768927e-03, -1.46243032e-02, -2.13061087e-02, ...,\n",
              "           -1.30402762e-02,  3.19686159e-02, -3.56891602e-02]],\n",
              " \n",
              "         [[-4.80278209e-03,  1.30781531e-03, -3.09724621e-02, ...,\n",
              "           -3.07837762e-02,  2.94925570e-02,  1.30132884e-02],\n",
              "          [-3.55094038e-02, -1.91961322e-02, -3.26984748e-03, ...,\n",
              "           -6.90668821e-05,  1.85503326e-02,  1.53330266e-02],\n",
              "          [-2.83901021e-03, -2.54430976e-02, -5.09530678e-03, ...,\n",
              "            3.81664187e-03,  3.10349837e-02,  2.51107290e-03],\n",
              "          ...,\n",
              "          [-1.13199558e-02, -3.78961116e-03, -3.41918021e-02, ...,\n",
              "            7.21192360e-03, -1.35103874e-02,  2.08996348e-02],\n",
              "          [ 1.85780786e-02, -2.43229456e-02,  3.01530436e-02, ...,\n",
              "            2.96598747e-02, -1.54353008e-02,  1.40326619e-02],\n",
              "          [-3.37478407e-02,  2.17998177e-02,  4.58394364e-03, ...,\n",
              "           -3.80557775e-03, -2.19294429e-03,  2.55011618e-02]],\n",
              " \n",
              "         [[-1.94574147e-03,  6.46483898e-03,  8.71638954e-03, ...,\n",
              "            2.50032842e-02,  1.27628744e-02,  1.33800842e-02],\n",
              "          [-4.56090271e-03, -6.48605637e-03,  1.24998838e-02, ...,\n",
              "            3.45285013e-02,  5.90286404e-03, -1.98229346e-02],\n",
              "          [-7.70887919e-03,  3.09788510e-02,  2.65631899e-02, ...,\n",
              "            3.32234800e-02,  1.53002813e-02,  1.44936219e-02],\n",
              "          ...,\n",
              "          [ 6.91151991e-03, -9.77798924e-03,  1.55532770e-02, ...,\n",
              "           -3.29425745e-02,  1.18523650e-02, -3.13251764e-02],\n",
              "          [ 5.80546632e-03, -1.03772692e-02, -3.40808704e-02, ...,\n",
              "            1.21586733e-02, -2.80215517e-02,  1.53085068e-02],\n",
              "          [-3.16046923e-03, -7.67540373e-03, -4.17598709e-03, ...,\n",
              "           -3.77597287e-03,  7.45856762e-03, -3.07102874e-03]]],\n",
              " \n",
              " \n",
              "        [[[-1.70622766e-03, -2.62048412e-02, -2.92456038e-02, ...,\n",
              "           -2.50364691e-02,  1.92871019e-02, -3.53597514e-02],\n",
              "          [-1.45216323e-02,  1.17687508e-02,  8.16109031e-03, ...,\n",
              "           -1.14537701e-02,  6.20556623e-03, -2.36793924e-02],\n",
              "          [ 2.78978124e-02,  6.40651211e-03,  3.60404402e-02, ...,\n",
              "            2.64280736e-02, -9.40842181e-03, -5.92332147e-03],\n",
              "          ...,\n",
              "          [ 3.15800905e-02,  4.78646904e-03,  2.85351127e-02, ...,\n",
              "            1.99152716e-02, -2.55867839e-04, -3.95191088e-03],\n",
              "          [ 2.25855038e-02,  1.05615668e-02,  1.16638467e-03, ...,\n",
              "            1.64458752e-02, -1.97146554e-02,  1.75754465e-02],\n",
              "          [-2.12697759e-02, -9.16915014e-03, -6.07915036e-03, ...,\n",
              "           -3.25550810e-02,  1.07364170e-02, -1.78183150e-02]],\n",
              " \n",
              "         [[-1.32605005e-02, -3.38189900e-02,  2.35854387e-02, ...,\n",
              "           -2.46391483e-02, -2.23198570e-02,  3.60701904e-02],\n",
              "          [-8.57505947e-04,  4.01681289e-03,  3.47816274e-02, ...,\n",
              "           -2.30881982e-02,  1.42568946e-02,  2.84748971e-02],\n",
              "          [ 7.24114850e-03,  3.22246253e-02, -3.41028869e-02, ...,\n",
              "           -3.25667113e-02, -1.23177711e-02, -2.60233916e-02],\n",
              "          ...,\n",
              "          [ 2.75149271e-02, -1.04921740e-02, -2.49766242e-02, ...,\n",
              "           -9.66638327e-04, -1.34237967e-02,  5.00604510e-05],\n",
              "          [-3.09818983e-03, -3.91681865e-03,  1.89561397e-04, ...,\n",
              "            3.04041952e-02, -1.49727240e-02,  1.57306492e-02],\n",
              "          [-2.74372846e-03, -3.07943858e-02, -2.86758319e-02, ...,\n",
              "           -1.29173696e-02, -1.10790059e-02,  3.50265577e-02]],\n",
              " \n",
              "         [[ 2.09290981e-02, -2.87874788e-03,  2.98535079e-02, ...,\n",
              "            1.44807436e-02,  2.17340030e-02, -3.36629190e-02],\n",
              "          [ 2.10242420e-02, -3.02690491e-02, -1.28396917e-02, ...,\n",
              "           -3.36597450e-02,  4.70531732e-03, -1.68295074e-02],\n",
              "          [ 1.44823864e-02,  1.44888982e-02, -2.41601039e-02, ...,\n",
              "           -2.67981701e-02, -1.87068433e-02,  1.53065026e-02],\n",
              "          ...,\n",
              "          [ 1.00155920e-03, -3.47009376e-02,  7.81599060e-03, ...,\n",
              "           -3.27108316e-02, -1.75388232e-02, -1.97450165e-02],\n",
              "          [-4.53006849e-03,  8.20227340e-03, -2.65382230e-04, ...,\n",
              "            8.02391768e-03,  1.26569420e-02, -2.20824778e-03],\n",
              "          [-4.76676971e-04,  3.13396528e-02,  2.47277580e-02, ...,\n",
              "           -3.38422097e-02,  1.67193338e-02,  2.99519524e-02]]],\n",
              " \n",
              " \n",
              "        [[[ 3.17803845e-02,  9.19629261e-03, -2.00179946e-02, ...,\n",
              "           -1.74126141e-02, -5.08274883e-04,  1.87238790e-02],\n",
              "          [ 3.67905200e-03,  3.13267559e-02,  1.30453333e-02, ...,\n",
              "           -1.01285689e-02,  6.94715232e-03, -2.49182954e-02],\n",
              "          [ 1.87587216e-02, -1.98314786e-02,  2.49694847e-02, ...,\n",
              "           -1.95836462e-02, -1.66742969e-02, -2.65608057e-02],\n",
              "          ...,\n",
              "          [-2.09399387e-02,  2.09845603e-05, -1.37678646e-02, ...,\n",
              "           -1.41039472e-02, -2.53500883e-02,  1.05001219e-02],\n",
              "          [ 7.91677460e-03, -3.23903784e-02, -3.51776853e-02, ...,\n",
              "           -3.63695621e-03, -1.33458097e-02, -7.34369084e-03],\n",
              "          [ 1.69002153e-02,  1.87799335e-04, -2.06121914e-02, ...,\n",
              "            2.48923823e-02,  8.45360383e-03, -3.08418237e-02]],\n",
              " \n",
              "         [[ 2.89446935e-02, -4.16938215e-04,  2.31364295e-02, ...,\n",
              "           -2.94424221e-03, -2.34568119e-02,  2.09389925e-02],\n",
              "          [ 1.90217644e-02, -3.59051712e-02,  3.99948657e-03, ...,\n",
              "           -2.26532295e-02,  8.91472772e-03,  1.88813061e-02],\n",
              "          [-2.44115666e-02,  7.69959763e-03,  3.16273868e-02, ...,\n",
              "            1.50265880e-02,  3.43842879e-02,  2.15097629e-02],\n",
              "          ...,\n",
              "          [ 8.55922699e-04, -9.85697471e-03,  8.94136727e-04, ...,\n",
              "           -9.34394076e-03, -2.60388516e-02,  2.13647485e-02],\n",
              "          [-8.10221769e-03, -3.63931432e-03, -3.55741978e-02, ...,\n",
              "            2.36286260e-02,  1.97208673e-02,  1.82217099e-02],\n",
              "          [ 1.39422603e-02, -3.44780460e-03,  4.66780737e-03, ...,\n",
              "           -3.44982892e-02, -2.65579764e-02, -2.58146860e-02]],\n",
              " \n",
              "         [[ 8.07729363e-03, -1.65781751e-03, -2.23936103e-02, ...,\n",
              "            8.64373520e-03, -1.41151156e-02, -2.28519458e-02],\n",
              "          [-2.08019689e-02,  5.52286208e-03, -8.56399350e-03, ...,\n",
              "            4.97323647e-03, -6.10657781e-03,  9.95483249e-04],\n",
              "          [ 1.71314366e-02, -2.92647295e-02,  3.77630815e-03, ...,\n",
              "           -2.77490448e-02, -3.13880220e-02,  3.37476954e-02],\n",
              "          ...,\n",
              "          [ 1.93110630e-02, -2.46814657e-02,  3.22796851e-02, ...,\n",
              "           -1.78211629e-02, -5.78554161e-03, -2.98512727e-03],\n",
              "          [ 2.17587836e-02, -1.70027148e-02,  1.23982541e-02, ...,\n",
              "           -6.18663058e-03, -2.37415321e-02,  2.34752372e-02],\n",
              "          [-2.21360996e-02,  3.24579626e-02, -1.96276773e-02, ...,\n",
              "           -2.59448364e-02, -2.16254666e-02, -1.86135080e-02]]]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'conv2d_9/bias:0' shape=(256,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.], dtype=float32)>,\n",
              " <tf.Variable 'conv2d_10/kernel:0' shape=(3, 3, 256, 256) dtype=float32, numpy=\n",
              " array([[[[-3.04798856e-02,  8.46572593e-03,  1.97905451e-02, ...,\n",
              "           -2.11693421e-02, -1.96617451e-02,  7.63401389e-03],\n",
              "          [-1.43301692e-02,  1.15355849e-02,  2.96350047e-02, ...,\n",
              "           -1.90945342e-03, -1.01822447e-02,  3.06643769e-02],\n",
              "          [ 5.47524169e-03,  1.17513724e-02,  3.52118015e-02, ...,\n",
              "           -1.73598528e-06,  3.20555493e-02, -2.18706578e-02],\n",
              "          ...,\n",
              "          [ 3.02503332e-02, -2.63967514e-02, -2.60123797e-02, ...,\n",
              "            5.21225110e-03, -3.17498371e-02, -2.30949782e-02],\n",
              "          [-8.03568028e-03, -5.31334430e-04,  6.76807761e-03, ...,\n",
              "           -1.07115563e-02, -2.30964758e-02, -1.51110813e-03],\n",
              "          [-1.56810507e-02,  3.19017023e-02,  2.51172967e-02, ...,\n",
              "           -1.00887027e-02,  2.73602083e-02,  3.02305296e-02]],\n",
              " \n",
              "         [[-9.54939425e-03, -1.72118098e-03,  2.16491930e-02, ...,\n",
              "           -2.29692943e-02,  1.04734711e-02,  2.02598907e-02],\n",
              "          [-3.28360833e-02, -2.70226337e-02, -4.63699177e-03, ...,\n",
              "           -2.44143885e-02, -1.74899399e-02, -5.00037149e-03],\n",
              "          [-2.93520764e-02, -3.34612019e-02, -3.45111787e-02, ...,\n",
              "            8.06704164e-04,  2.50139013e-02,  1.71640925e-02],\n",
              "          ...,\n",
              "          [ 1.41393505e-02,  2.48347670e-02, -2.02833787e-02, ...,\n",
              "            7.27790967e-03,  3.41112688e-02,  2.24891938e-02],\n",
              "          [ 2.85644904e-02,  2.54116952e-02, -1.31602120e-02, ...,\n",
              "            3.25405896e-02, -5.61601482e-03, -2.81312242e-02],\n",
              "          [-2.60095317e-02,  1.69503577e-02,  1.06730722e-02, ...,\n",
              "            6.82149455e-03,  9.59520414e-03,  1.38358735e-02]],\n",
              " \n",
              "         [[ 1.72491036e-02, -3.55847515e-02,  2.12512538e-03, ...,\n",
              "            2.41501853e-02,  1.98104084e-02, -2.78814733e-02],\n",
              "          [ 2.07480192e-02,  7.66627491e-05, -2.67188214e-02, ...,\n",
              "            1.52210891e-02, -1.63184181e-02, -1.53395385e-02],\n",
              "          [ 3.36925462e-02, -2.93908436e-02, -3.44480388e-02, ...,\n",
              "            1.71477124e-02, -1.58716459e-02,  2.58948244e-02],\n",
              "          ...,\n",
              "          [-3.12410370e-02,  1.86439455e-02,  2.35960893e-02, ...,\n",
              "           -2.16060318e-02,  2.93134302e-02,  3.49078998e-02],\n",
              "          [-1.50960330e-02, -2.89678425e-02,  2.02198103e-02, ...,\n",
              "           -3.27133760e-03, -2.03674231e-02, -2.91142594e-02],\n",
              "          [-1.18540842e-02,  1.34449340e-02, -1.28760152e-02, ...,\n",
              "            3.14061344e-02,  2.66565681e-02, -2.19730269e-02]]],\n",
              " \n",
              " \n",
              "        [[[ 2.29425393e-02, -3.52935344e-02,  8.67226347e-03, ...,\n",
              "            4.95424867e-03, -1.03032663e-02,  6.85274974e-03],\n",
              "          [ 7.81371072e-03,  5.24330884e-03,  1.98769644e-02, ...,\n",
              "           -5.70777804e-03,  1.40255801e-02, -1.76596120e-02],\n",
              "          [ 3.50249633e-02,  1.90188736e-02, -2.93382257e-02, ...,\n",
              "            1.89305469e-03, -1.85219776e-02,  2.48692408e-02],\n",
              "          ...,\n",
              "          [ 1.28731914e-02, -5.32877259e-03, -1.03620067e-03, ...,\n",
              "            3.29533964e-02,  1.80221498e-02,  3.56519446e-02],\n",
              "          [ 1.22403242e-02, -1.38242915e-03,  2.10045278e-03, ...,\n",
              "           -3.45846564e-02, -1.80759374e-02,  1.05508380e-02],\n",
              "          [ 2.84947455e-02,  7.24058971e-03, -5.32445312e-03, ...,\n",
              "            2.62510926e-02,  1.50327757e-03, -1.83459651e-02]],\n",
              " \n",
              "         [[ 2.32882239e-02, -1.06000062e-02,  1.90192685e-02, ...,\n",
              "           -4.62718308e-03,  2.77039558e-02,  1.64828859e-02],\n",
              "          [ 4.31611761e-03, -2.58204769e-02, -2.35720836e-02, ...,\n",
              "           -1.74639747e-03, -3.56525034e-02, -1.93463620e-02],\n",
              "          [-2.17220299e-02, -1.19322110e-02,  9.33129340e-04, ...,\n",
              "           -2.12408453e-02,  3.12640965e-02, -2.42732279e-02],\n",
              "          ...,\n",
              "          [ 1.16234422e-02, -1.03604160e-02,  1.50331259e-02, ...,\n",
              "            2.14985013e-02, -1.86612029e-02, -3.23750153e-02],\n",
              "          [ 2.95423642e-02,  5.32893464e-03,  7.09983334e-03, ...,\n",
              "           -1.13349687e-02, -1.19935088e-02,  2.14633644e-02],\n",
              "          [-8.75785761e-03, -2.09316611e-03,  3.83943319e-04, ...,\n",
              "           -9.67965461e-03, -1.37264319e-02,  2.07940117e-02]],\n",
              " \n",
              "         [[-1.16242245e-02,  1.02067217e-02,  2.69640461e-02, ...,\n",
              "            1.08754896e-02,  1.18117407e-03,  2.37005204e-02],\n",
              "          [-1.70034803e-02, -2.77153365e-02, -1.39496848e-02, ...,\n",
              "            9.48379561e-03, -1.47844106e-03, -1.07350424e-02],\n",
              "          [ 1.25770457e-02, -1.47933513e-03, -4.68248501e-03, ...,\n",
              "           -1.56772565e-02, -7.24469498e-03, -6.30546361e-04],\n",
              "          ...,\n",
              "          [ 2.99010277e-02, -1.41511802e-02,  1.09262653e-02, ...,\n",
              "            2.63267905e-02, -1.34338625e-02,  3.11878175e-02],\n",
              "          [ 2.05182657e-03,  2.68889591e-02, -3.08994204e-02, ...,\n",
              "            3.57959718e-02,  1.94580145e-02,  1.65262967e-02],\n",
              "          [ 3.32069993e-02, -3.01553495e-02, -2.77079307e-02, ...,\n",
              "           -2.22358033e-02, -1.22521538e-02,  1.10356621e-02]]],\n",
              " \n",
              " \n",
              "        [[[-3.40784714e-02,  1.85754485e-02, -1.09670442e-02, ...,\n",
              "            8.01792368e-03,  2.58837603e-02, -1.98059902e-03],\n",
              "          [ 8.00496712e-03, -2.97782868e-02,  1.26165263e-02, ...,\n",
              "           -5.37011027e-03,  3.14324349e-03, -2.72355899e-02],\n",
              "          [-3.55340876e-02, -1.57048032e-02, -1.41487271e-03, ...,\n",
              "           -2.84798425e-02, -2.61752121e-02,  2.38919072e-02],\n",
              "          ...,\n",
              "          [ 2.05612108e-02,  2.38336399e-02, -1.63438581e-02, ...,\n",
              "            1.18706375e-02,  3.33526731e-02,  1.05874389e-02],\n",
              "          [ 3.16364244e-02, -1.78270638e-02, -3.25249508e-02, ...,\n",
              "           -3.30177322e-03,  8.92121345e-03,  1.87979788e-02],\n",
              "          [-4.45454195e-03, -3.42913643e-02, -2.87801288e-02, ...,\n",
              "           -3.19775455e-02, -2.91845948e-03,  1.29316524e-02]],\n",
              " \n",
              "         [[-3.56968604e-02, -6.55974261e-03,  1.30364820e-02, ...,\n",
              "            3.78428400e-03, -8.24927166e-03,  4.19845805e-03],\n",
              "          [ 4.89314273e-03,  2.07455754e-02, -2.70026755e-02, ...,\n",
              "            2.08009966e-02, -2.23259479e-02,  9.58319753e-03],\n",
              "          [ 6.81096315e-03,  7.11753964e-03, -2.17893403e-02, ...,\n",
              "            1.27284229e-03, -1.92175433e-03, -1.40198171e-02],\n",
              "          ...,\n",
              "          [-1.58889554e-02, -3.30555700e-02, -2.14461330e-02, ...,\n",
              "           -2.45686881e-02, -1.15565695e-02,  2.89876238e-02],\n",
              "          [-3.27077247e-02, -1.73752513e-02,  1.57248229e-03, ...,\n",
              "            1.34763010e-02, -1.13113783e-02,  2.39005014e-02],\n",
              "          [-3.27267312e-02, -4.96242195e-03, -2.73099542e-03, ...,\n",
              "           -2.52692029e-03, -2.46417895e-02,  2.84047127e-02]],\n",
              " \n",
              "         [[ 5.43169677e-04, -2.21788920e-02,  8.59046355e-03, ...,\n",
              "            3.54365110e-02, -1.82323270e-02,  2.72632390e-03],\n",
              "          [-3.14313918e-03, -3.41033600e-02, -1.72408670e-03, ...,\n",
              "           -1.11814365e-02, -1.19621847e-02, -1.64797194e-02],\n",
              "          [ 2.65138224e-02,  3.69551033e-03,  6.07702881e-04, ...,\n",
              "            2.81610861e-02, -5.07295690e-03,  3.20773199e-03],\n",
              "          ...,\n",
              "          [-2.24516746e-02, -3.49064954e-02, -1.15359388e-02, ...,\n",
              "            4.69519943e-03, -2.13746764e-02, -1.35081168e-02],\n",
              "          [ 1.65525191e-02, -4.64116409e-03,  2.85306945e-02, ...,\n",
              "           -4.76554781e-03, -8.24435800e-03, -9.37662460e-03],\n",
              "          [-2.94177029e-02, -3.74777243e-03, -1.57116093e-02, ...,\n",
              "            1.52219161e-02, -3.99817899e-03,  3.18671912e-02]]]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'conv2d_10/bias:0' shape=(256,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.], dtype=float32)>,\n",
              " <tf.Variable 'dense_1/kernel:0' shape=(16384, 512) dtype=float32, numpy=\n",
              " array([[ 0.01851832, -0.00919689, -0.01571156, ..., -0.01807607,\n",
              "         -0.00569668, -0.00981924],\n",
              "        [-0.00864305, -0.0018876 , -0.00078282, ..., -0.00693397,\n",
              "         -0.00806528,  0.01081293],\n",
              "        [ 0.01525798,  0.01229795, -0.01596892, ...,  0.01030079,\n",
              "         -0.00435738, -0.00849098],\n",
              "        ...,\n",
              "        [-0.00468978, -0.01406374,  0.01475443, ...,  0.01495773,\n",
              "          0.00164608, -0.01288734],\n",
              "        [-0.01765614,  0.00102597, -0.00262716, ..., -0.01187101,\n",
              "          0.01447812, -0.00807904],\n",
              "        [-0.00975079, -0.0030362 ,  0.00498559, ..., -0.01063837,\n",
              "         -0.00811994,  0.00827477]], dtype=float32)>,\n",
              " <tf.Variable 'dense_1/bias:0' shape=(512,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'dense_2/kernel:0' shape=(512, 109) dtype=float32, numpy=\n",
              " array([[-0.09432067, -0.00170346, -0.0673831 , ...,  0.00067529,\n",
              "         -0.09471797, -0.06261712],\n",
              "        [ 0.06438936, -0.02826504,  0.0826587 , ..., -0.08905786,\n",
              "          0.01839066, -0.08432593],\n",
              "        [ 0.04983484, -0.03435414, -0.08429739, ..., -0.05658743,\n",
              "          0.0423945 ,  0.00900106],\n",
              "        ...,\n",
              "        [-0.00846215, -0.00551826, -0.09736885, ..., -0.05735632,\n",
              "         -0.09575219, -0.07112744],\n",
              "        [-0.0195003 ,  0.05780993,  0.00385302, ...,  0.03441938,\n",
              "          0.02733029, -0.07719912],\n",
              "        [-0.07632778,  0.08438515,  0.01272015, ..., -0.08342329,\n",
              "         -0.03109462,  0.0621851 ]], dtype=float32)>,\n",
              " <tf.Variable 'dense_2/bias:0' shape=(109,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rl9nvCwmZgp0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4e520e5b-9a10-4d85-b0fd-ca02d7adab9a"
      },
      "source": [
        "model.layers[0].get_weights()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[[ 0.04482017, -0.06483161, -0.03653897, -0.02644072,\n",
              "            0.11282937, -0.04154134, -0.09601479,  0.1378886 ,\n",
              "           -0.02752429,  0.05950691,  0.12296759, -0.07441309,\n",
              "            0.009966  , -0.11023463,  0.05360009, -0.03499044,\n",
              "           -0.09472683,  0.08473286,  0.02483855, -0.00056405,\n",
              "            0.01044095,  0.0611151 , -0.06798614, -0.08616297,\n",
              "           -0.01476044,  0.02987106, -0.07433896,  0.035748  ,\n",
              "            0.05886728,  0.13016619, -0.10040332, -0.11743146],\n",
              "          [-0.12111112,  0.10023445,  0.08119571, -0.10250866,\n",
              "           -0.00837891,  0.00016423, -0.03262638, -0.05643583,\n",
              "            0.13478391, -0.07046263,  0.13798277,  0.04076751,\n",
              "           -0.02340117, -0.10515639,  0.12990959,  0.10659358,\n",
              "            0.01609473, -0.03018622,  0.02220702,  0.1253518 ,\n",
              "           -0.11216731,  0.03130692,  0.0300747 , -0.0913261 ,\n",
              "            0.13452931, -0.12525362,  0.06522717, -0.05666403,\n",
              "            0.09920445, -0.0592316 , -0.04977816,  0.05320396],\n",
              "          [-0.10567869, -0.02813885, -0.06704424, -0.08070059,\n",
              "            0.12732671, -0.1059849 ,  0.04561052,  0.07456225,\n",
              "            0.03934984,  0.08073129, -0.11597095, -0.10629553,\n",
              "           -0.05171612,  0.08811876, -0.02203575,  0.07195581,\n",
              "           -0.12177659,  0.01528083,  0.09165651,  0.08250038,\n",
              "           -0.10061862,  0.13255559,  0.08172475,  0.10851644,\n",
              "           -0.09920304, -0.02097841, -0.1322207 , -0.00513178,\n",
              "            0.00674161, -0.03436376, -0.09296504,  0.00269307]],\n",
              " \n",
              "         [[-0.0711508 , -0.11765127, -0.05722025,  0.0965303 ,\n",
              "            0.12956227, -0.10847673, -0.0895807 ,  0.0756797 ,\n",
              "            0.02508281,  0.12526412,  0.02601527,  0.08237611,\n",
              "           -0.1372838 ,  0.06293316,  0.06653455,  0.132625  ,\n",
              "           -0.0542702 ,  0.00709923, -0.08307175,  0.02503154,\n",
              "           -0.06852881, -0.02654322, -0.10216218, -0.03713692,\n",
              "           -0.13783301,  0.0292822 , -0.12650624, -0.09283197,\n",
              "           -0.04775562, -0.01471793,  0.11827035, -0.09406711],\n",
              "          [-0.05987755,  0.02269299,  0.1043008 ,  0.11143912,\n",
              "            0.00925045, -0.0877373 , -0.03679224, -0.06722943,\n",
              "           -0.05547801, -0.0670833 ,  0.0175714 , -0.08642015,\n",
              "            0.09573424,  0.00900841, -0.09713106,  0.05602722,\n",
              "            0.06467706, -0.11497764, -0.0762677 , -0.07305577,\n",
              "           -0.03392833,  0.00340171,  0.07670166, -0.12081958,\n",
              "           -0.10178153, -0.04045383,  0.12160279,  0.01692273,\n",
              "           -0.10691585,  0.03639765, -0.08438452,  0.08678375],\n",
              "          [ 0.11853017,  0.00379755,  0.00309759, -0.13576752,\n",
              "            0.04992369,  0.03661054, -0.07499429,  0.02689435,\n",
              "            0.10538143,  0.08183526,  0.04981998, -0.03702962,\n",
              "           -0.06104857, -0.08859427,  0.13016336, -0.05749869,\n",
              "            0.11493339,  0.08809932, -0.04962274,  0.02230543,\n",
              "           -0.04658224, -0.07936676, -0.05006235, -0.10580774,\n",
              "           -0.08475313, -0.00656009,  0.09037954, -0.01166768,\n",
              "           -0.08412287,  0.01427734, -0.10833786, -0.12126406]],\n",
              " \n",
              "         [[-0.04079219,  0.10552098, -0.12351087,  0.04965793,\n",
              "            0.04563165, -0.12595505,  0.03456786,  0.0306257 ,\n",
              "           -0.03159402,  0.07487722,  0.06543295,  0.08847417,\n",
              "           -0.12538405, -0.12034091, -0.0890784 ,  0.05121492,\n",
              "            0.05603038, -0.06770638,  0.09553817, -0.06498719,\n",
              "            0.0469583 , -0.04718005, -0.07294317, -0.08281973,\n",
              "            0.06698129,  0.00716905,  0.11260147, -0.03094761,\n",
              "            0.02502374, -0.09079933, -0.01717194, -0.11811884],\n",
              "          [ 0.13148238, -0.09736247,  0.03426811,  0.04575698,\n",
              "           -0.07388029,  0.04619636, -0.02680478,  0.12528099,\n",
              "           -0.08703682,  0.01814701, -0.01230679, -0.13098723,\n",
              "            0.04282141, -0.02816777,  0.09139018, -0.02490936,\n",
              "            0.11291717, -0.07511594,  0.10787773,  0.04385202,\n",
              "            0.09123552,  0.03162867, -0.05069476,  0.06752905,\n",
              "            0.10899533,  0.0762893 , -0.04391138,  0.0637144 ,\n",
              "           -0.0793127 ,  0.03116547,  0.02272688, -0.10062858],\n",
              "          [-0.04223599,  0.09561443, -0.01568968,  0.0957576 ,\n",
              "           -0.08249545,  0.09424165, -0.00680634,  0.08747965,\n",
              "            0.06383707,  0.01114252, -0.01525457,  0.06997693,\n",
              "            0.00708304,  0.07227901,  0.11256282,  0.04669704,\n",
              "           -0.03711905, -0.0202729 , -0.10343596, -0.04040892,\n",
              "           -0.05573713, -0.04762374,  0.11261506,  0.11083058,\n",
              "           -0.12425616, -0.05885527,  0.08924893, -0.12908608,\n",
              "           -0.10940172, -0.03975648, -0.06711048,  0.00066049]]],\n",
              " \n",
              " \n",
              "        [[[ 0.04936682, -0.05045129,  0.06544627, -0.10310471,\n",
              "           -0.1320236 ,  0.10309586, -0.07644822,  0.10725644,\n",
              "            0.06428681,  0.03014117, -0.11868287,  0.06214082,\n",
              "           -0.11880623, -0.12074818,  0.09634914, -0.03970909,\n",
              "           -0.0585502 , -0.08348793, -0.11036764,  0.05798967,\n",
              "            0.04876448,  0.02047884, -0.1311301 , -0.11528126,\n",
              "           -0.12267989,  0.04668148,  0.11353548, -0.10801066,\n",
              "           -0.1113819 ,  0.01635876,  0.10249491, -0.00584576],\n",
              "          [-0.11395421, -0.02609561,  0.13370968, -0.04597731,\n",
              "           -0.11151391,  0.02313003,  0.05181256, -0.00897439,\n",
              "            0.04314631,  0.09336677, -0.08450486, -0.0381444 ,\n",
              "           -0.04018836,  0.06427723, -0.11492286,  0.04228841,\n",
              "           -0.1067894 ,  0.11884169,  0.00570196,  0.11468546,\n",
              "            0.01433448, -0.13650863,  0.11137055, -0.01376773,\n",
              "           -0.10166815,  0.06404571,  0.0579361 , -0.00890723,\n",
              "            0.13375075,  0.10928853, -0.06160332, -0.04414191],\n",
              "          [ 0.10514133,  0.00181602,  0.12295635, -0.10230288,\n",
              "           -0.00538759,  0.0602546 ,  0.13644274,  0.03719369,\n",
              "            0.11866583,  0.05943498,  0.11002639, -0.03420858,\n",
              "           -0.05118649,  0.13400479,  0.11002351, -0.0968641 ,\n",
              "           -0.11344095, -0.02843792, -0.01437999, -0.07664072,\n",
              "           -0.12016638, -0.08091378,  0.03735127, -0.01368228,\n",
              "           -0.1194053 ,  0.09783123, -0.02899029,  0.006651  ,\n",
              "            0.10053599,  0.097247  ,  0.13771914,  0.07053594]],\n",
              " \n",
              "         [[ 0.04912752, -0.00874859, -0.10134466,  0.07614079,\n",
              "            0.04185437,  0.00684273,  0.05374846,  0.13762017,\n",
              "            0.09230591, -0.00588813, -0.0021683 ,  0.05162521,\n",
              "           -0.10039058,  0.11873393,  0.01192214,  0.07009166,\n",
              "           -0.11585545,  0.02420595,  0.00381094,  0.05815172,\n",
              "           -0.12103922,  0.06808907, -0.0184499 ,  0.00335659,\n",
              "            0.01929273,  0.12092493,  0.09060864,  0.10444038,\n",
              "           -0.10747678,  0.05965716,  0.08150801, -0.08722593],\n",
              "          [ 0.00583509, -0.06583673,  0.05022846, -0.05774601,\n",
              "            0.06746276,  0.07433248, -0.00248402, -0.01477571,\n",
              "            0.02736653, -0.02186816,  0.11425103, -0.01038258,\n",
              "            0.11986373, -0.03414409,  0.12207927, -0.07809995,\n",
              "           -0.0852083 ,  0.02276637,  0.0502743 , -0.12850073,\n",
              "            0.11886482,  0.11784668, -0.0866775 , -0.13351889,\n",
              "            0.03730105, -0.07053804, -0.13405031, -0.01902889,\n",
              "           -0.01783998, -0.07981327,  0.08116096,  0.09368013],\n",
              "          [-0.08869566, -0.09752364, -0.08587268,  0.13391037,\n",
              "           -0.01416703,  0.10549982,  0.02131096,  0.11829104,\n",
              "           -0.03434583, -0.11712005,  0.00726761, -0.0150305 ,\n",
              "           -0.0335416 ,  0.09972331, -0.02943059,  0.01911132,\n",
              "           -0.0049814 , -0.02873442,  0.02117531,  0.00780267,\n",
              "           -0.02893972,  0.03181146, -0.13165069,  0.09265395,\n",
              "           -0.02370725,  0.0713582 ,  0.03027157, -0.03576498,\n",
              "            0.10288185, -0.02335688,  0.07017051,  0.06700225]],\n",
              " \n",
              "         [[-0.07086436,  0.11118904, -0.10651971, -0.12030821,\n",
              "           -0.11046655,  0.13140689, -0.04152083,  0.11460315,\n",
              "            0.08725981, -0.0914391 , -0.01880527, -0.05210292,\n",
              "           -0.1344817 ,  0.01308413,  0.07785353,  0.08715455,\n",
              "           -0.07041176, -0.08596326,  0.07831788, -0.13709049,\n",
              "           -0.09403257,  0.009831  , -0.04778642,  0.00133176,\n",
              "            0.0364857 , -0.00659862, -0.08599509,  0.06230834,\n",
              "           -0.0802801 ,  0.0457983 ,  0.12047412, -0.02009459],\n",
              "          [-0.11619483, -0.09305944, -0.0694183 ,  0.11932404,\n",
              "            0.1324196 , -0.03075083, -0.09295615,  0.07275206,\n",
              "           -0.07318166,  0.11044069,  0.06188604, -0.06998669,\n",
              "            0.11498643,  0.04412101,  0.02900164, -0.05576141,\n",
              "           -0.04030553,  0.11437537, -0.10397646, -0.0838972 ,\n",
              "            0.0722485 ,  0.08484229, -0.02839774,  0.1100179 ,\n",
              "           -0.1192566 ,  0.07449098,  0.13225712,  0.11791082,\n",
              "            0.10289484, -0.12524042, -0.0343455 , -0.13559532],\n",
              "          [-0.0724387 ,  0.08527842, -0.07697415,  0.1235268 ,\n",
              "            0.10828903, -0.06849933,  0.07207651,  0.04699163,\n",
              "           -0.00670688, -0.01293747,  0.08657961,  0.05464667,\n",
              "           -0.00266519, -0.09850945,  0.12443577,  0.0008889 ,\n",
              "           -0.08269913, -0.07871425, -0.01551864, -0.05450642,\n",
              "           -0.07956554,  0.05035467, -0.09664521, -0.00382467,\n",
              "           -0.01048215, -0.1131203 ,  0.10190128,  0.06416039,\n",
              "            0.03520304, -0.12560122, -0.05377422,  0.02803718]]],\n",
              " \n",
              " \n",
              "        [[[-0.01961375,  0.09606691, -0.11612014,  0.10100195,\n",
              "           -0.08170794, -0.06616551, -0.1143414 , -0.11347027,\n",
              "           -0.10248912,  0.12008481,  0.06603047,  0.12664135,\n",
              "           -0.00660563, -0.12104458, -0.0436661 , -0.00020997,\n",
              "            0.02770776, -0.12507918,  0.1146998 ,  0.1358604 ,\n",
              "           -0.07462   ,  0.1053144 , -0.00023767,  0.07900533,\n",
              "            0.02813539, -0.13727236,  0.04610804,  0.05434963,\n",
              "           -0.09829987,  0.136894  ,  0.09355834,  0.11205368],\n",
              "          [ 0.03030096,  0.06081173,  0.06239133, -0.04723392,\n",
              "           -0.0903103 ,  0.10293087,  0.1281756 ,  0.0267064 ,\n",
              "           -0.01957054, -0.00945081, -0.01095785, -0.09120077,\n",
              "            0.0641007 , -0.01606289, -0.09685676, -0.10621047,\n",
              "           -0.06529304,  0.09469211, -0.00704981, -0.07573919,\n",
              "            0.03715679,  0.01332405, -0.02007419, -0.08817118,\n",
              "            0.05021454,  0.10205349,  0.02286899, -0.05805212,\n",
              "           -0.06589174, -0.13703501,  0.00349693,  0.08853127],\n",
              "          [ 0.11749865, -0.131048  , -0.0928628 ,  0.06652375,\n",
              "           -0.09470303, -0.10610484, -0.10441926,  0.09374632,\n",
              "           -0.0370669 ,  0.13789152, -0.05286085, -0.02821393,\n",
              "            0.02130684,  0.04910311,  0.05085063,  0.05599391,\n",
              "            0.06282212,  0.11753838,  0.04050744, -0.04337279,\n",
              "           -0.01932139, -0.01942511, -0.02927551,  0.13763608,\n",
              "           -0.03340221,  0.03457469,  0.11901771, -0.08204837,\n",
              "            0.04663409, -0.11472609, -0.01692989, -0.10115591]],\n",
              " \n",
              "         [[-0.04857798, -0.00305749,  0.03374314,  0.03323144,\n",
              "           -0.06100468, -0.06182723, -0.02542498, -0.05570785,\n",
              "           -0.00277852, -0.07798636, -0.01914469,  0.03196542,\n",
              "           -0.10662711, -0.12005392,  0.00768876,  0.11540188,\n",
              "           -0.09528973,  0.06591949,  0.00499684,  0.02070946,\n",
              "            0.08833219, -0.06569   , -0.03848339, -0.0438713 ,\n",
              "            0.03693587,  0.10995722,  0.03935763, -0.09948145,\n",
              "           -0.10487844, -0.04064327, -0.02081761, -0.01069357],\n",
              "          [-0.0019151 ,  0.02541731,  0.06906874, -0.1269982 ,\n",
              "           -0.1068862 , -0.0592185 ,  0.13092788,  0.01477729,\n",
              "            0.05699761, -0.00790849, -0.02073465,  0.05655274,\n",
              "            0.13466276, -0.02178188, -0.00908791,  0.08028553,\n",
              "            0.00342171, -0.07494473,  0.06705566,  0.06225401,\n",
              "            0.0079546 , -0.12943783,  0.12271489, -0.09915214,\n",
              "            0.02604425,  0.06935301, -0.0530518 ,  0.02917193,\n",
              "           -0.0521682 ,  0.11653484, -0.09528187,  0.01572134],\n",
              "          [-0.05750297,  0.12126569, -0.1322743 , -0.07663342,\n",
              "           -0.09287435, -0.0048819 , -0.08102082, -0.06322928,\n",
              "            0.1105704 , -0.00678943,  0.0467408 ,  0.03043887,\n",
              "           -0.0563307 , -0.07151592,  0.04276656,  0.06047833,\n",
              "            0.04948471,  0.01078287,  0.07551695,  0.08073093,\n",
              "           -0.09710637, -0.11794393, -0.0152476 ,  0.05730797,\n",
              "           -0.09439389,  0.08999796,  0.07108776,  0.02262908,\n",
              "           -0.11169019,  0.1228206 ,  0.01099257,  0.12195639]],\n",
              " \n",
              "         [[-0.04420229,  0.00096045, -0.04290182, -0.11260448,\n",
              "           -0.02299305, -0.10366669, -0.08912474,  0.07608144,\n",
              "            0.06023994,  0.03769018, -0.10273281,  0.02744968,\n",
              "            0.09164035,  0.04756688, -0.13643469,  0.08074507,\n",
              "            0.00096412,  0.11634122,  0.04279278, -0.07297018,\n",
              "           -0.00120324,  0.09625164,  0.04544672, -0.12431625,\n",
              "            0.03370659,  0.0672881 , -0.06312918, -0.02833713,\n",
              "           -0.00181259, -0.09935845, -0.12258496,  0.01323688],\n",
              "          [-0.00667123, -0.08757133,  0.07489248,  0.0858787 ,\n",
              "            0.01509765, -0.02245469, -0.0376398 , -0.10937326,\n",
              "            0.01682502, -0.07070863,  0.06134811, -0.00761281,\n",
              "           -0.00115141,  0.06502618, -0.07943168, -0.13205539,\n",
              "           -0.08149058, -0.09579252,  0.03718591, -0.04577929,\n",
              "            0.00417177, -0.09790803,  0.12152945,  0.04004607,\n",
              "            0.04246938, -0.09039365,  0.12153088,  0.08923088,\n",
              "            0.00275607,  0.01869498, -0.07009949, -0.11231143],\n",
              "          [ 0.03988573,  0.04888462, -0.10589682,  0.02883488,\n",
              "           -0.0039217 , -0.11578865, -0.09375435, -0.11787377,\n",
              "           -0.01512749, -0.07419065, -0.10174284, -0.10258155,\n",
              "           -0.13475214, -0.08914109, -0.09671661, -0.13649435,\n",
              "           -0.09005433, -0.01148508, -0.10686738, -0.10924019,\n",
              "            0.00840512, -0.08564909,  0.04303858,  0.04098597,\n",
              "            0.10791297, -0.04051395, -0.08574616,  0.13579978,\n",
              "            0.09966233,  0.01487963, -0.13705324, -0.11614623]]]],\n",
              "       dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woTegVl5ZnZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "f7ca1147-0402-4449-876b-38480f018e05"
      },
      "source": [
        "hist = model.fit(X_train, y_train, batch_size=batch_size, epochs=20, verbose=1, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1744 samples, validate on 436 samples\n",
            "Epoch 1/20\n",
            "1744/1744 [==============================] - 328s 188ms/step - loss: 4.6912 - accuracy: 0.0052 - val_loss: 4.6620 - val_accuracy: 0.0252\n",
            "Epoch 2/20\n",
            "1744/1744 [==============================] - 330s 189ms/step - loss: 4.9134 - accuracy: 0.0241 - val_loss: 4.6921 - val_accuracy: 0.0092\n",
            "Epoch 3/20\n",
            "1744/1744 [==============================] - 318s 182ms/step - loss: 4.6913 - accuracy: 0.0092 - val_loss: 4.6934 - val_accuracy: 0.0092\n",
            "Epoch 4/20\n",
            "1744/1744 [==============================] - 319s 183ms/step - loss: 4.6911 - accuracy: 0.0086 - val_loss: 4.6967 - val_accuracy: 0.0046\n",
            "Epoch 5/20\n",
            "1744/1744 [==============================] - 319s 183ms/step - loss: 4.6856 - accuracy: 0.0080 - val_loss: 4.7219 - val_accuracy: 0.0092\n",
            "Epoch 6/20\n",
            "1744/1744 [==============================] - 322s 185ms/step - loss: 4.6742 - accuracy: 0.0155 - val_loss: 4.6734 - val_accuracy: 0.0275\n",
            "Epoch 7/20\n",
            "1744/1744 [==============================] - 319s 183ms/step - loss: 4.5941 - accuracy: 0.0401 - val_loss: 4.4921 - val_accuracy: 0.0229\n",
            "Epoch 8/20\n",
            "1744/1744 [==============================] - 321s 184ms/step - loss: 4.2226 - accuracy: 0.0625 - val_loss: 3.6612 - val_accuracy: 0.1193\n",
            "Epoch 9/20\n",
            "1744/1744 [==============================] - 324s 186ms/step - loss: 3.8109 - accuracy: 0.1393 - val_loss: 3.4416 - val_accuracy: 0.2362\n",
            "Epoch 10/20\n",
            "1744/1744 [==============================] - 318s 182ms/step - loss: 3.1716 - accuracy: 0.2397 - val_loss: 2.3021 - val_accuracy: 0.4702\n",
            "Epoch 11/20\n",
            "1744/1744 [==============================] - 323s 185ms/step - loss: 2.1245 - accuracy: 0.4346 - val_loss: 1.3300 - val_accuracy: 0.7248\n",
            "Epoch 12/20\n",
            "1744/1744 [==============================] - 326s 187ms/step - loss: 1.2527 - accuracy: 0.6583 - val_loss: 0.4565 - val_accuracy: 0.9220\n",
            "Epoch 13/20\n",
            "1744/1744 [==============================] - 324s 186ms/step - loss: 0.6283 - accuracy: 0.8211 - val_loss: 0.2584 - val_accuracy: 0.9381\n",
            "Epoch 14/20\n",
            "1744/1744 [==============================] - 320s 183ms/step - loss: 0.3216 - accuracy: 0.9077 - val_loss: 0.1164 - val_accuracy: 0.9725\n",
            "Epoch 15/20\n",
            "1744/1744 [==============================] - 321s 184ms/step - loss: 0.1402 - accuracy: 0.9593 - val_loss: 0.0888 - val_accuracy: 0.9862\n",
            "Epoch 16/20\n",
            "1744/1744 [==============================] - 319s 183ms/step - loss: 0.0744 - accuracy: 0.9725 - val_loss: 0.0629 - val_accuracy: 0.9908\n",
            "Epoch 17/20\n",
            "1744/1744 [==============================] - 317s 182ms/step - loss: 0.0691 - accuracy: 0.9828 - val_loss: 0.0486 - val_accuracy: 0.9908\n",
            "Epoch 18/20\n",
            "1744/1744 [==============================] - 321s 184ms/step - loss: 0.0311 - accuracy: 0.9891 - val_loss: 0.0504 - val_accuracy: 0.9931\n",
            "Epoch 19/20\n",
            "1744/1744 [==============================] - 326s 187ms/step - loss: 0.0221 - accuracy: 0.9914 - val_loss: 0.0486 - val_accuracy: 0.9908\n",
            "Epoch 20/20\n",
            "1744/1744 [==============================] - 321s 184ms/step - loss: 0.0119 - accuracy: 0.9948 - val_loss: 0.0500 - val_accuracy: 0.9885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slK5BJaeZxmT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9c7f37a7-7de0-4ab3-fb4f-814d7e12ae41"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "\n",
        "print('Test Loss:', score[0])\n",
        "print('Test Accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r436/436 [==============================] - 15s 35ms/step\n",
            "Test Loss: 0.04995255544781685\n",
            "Test Accuracy: 0.9885321259498596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk975bR00xYw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "ae399c18-74b7-4efa-b007-663c2cc18888"
      },
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "print(Y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.46943503e-12 3.55973206e-09 9.71630675e-12 ... 6.30566106e-08\n",
            "  9.53628496e-12 1.27506797e-13]\n",
            " [1.55891811e-07 6.67085354e-12 3.16649096e-10 ... 2.05936483e-12\n",
            "  4.55833815e-10 2.54269889e-05]\n",
            " [2.71359763e-16 6.67935571e-22 1.48962490e-17 ... 3.47144710e-23\n",
            "  2.65572258e-27 3.76279345e-29]\n",
            " ...\n",
            " [2.85445224e-14 1.70560299e-14 2.44776161e-11 ... 2.65075251e-08\n",
            "  1.14433610e-11 2.95719838e-10]\n",
            " [2.68122181e-14 4.01385663e-15 1.48144871e-10 ... 7.14137882e-14\n",
            "  7.29118210e-06 1.66670961e-05]\n",
            " [4.98264167e-15 8.65810462e-12 4.85644407e-11 ... 4.62045020e-11\n",
            "  1.84708759e-12 1.03505705e-13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afOZc-Pi0lQK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "6f40a1c3-c674-4be5-d000-1bac7446cf7b"
      },
      "source": [
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 53  23  48  59  92  66  50  64  82  71  31  38  97  99 104  64 104  52\n",
            "  67  16  93  65   4   3  93  66  12  85  55  32  77 106  27  41  27  89\n",
            " 107  97   4 101  75   0  63  73  30  60  43 102  34   5  90  53  92  93\n",
            "  90  54  96   4  91  30  57  85  94  96  18 106  28 105  47  24  76  57\n",
            "  61  77  93  41  40 107  58  79  51  39  46  40  21  34   2  71  92  25\n",
            "   4  40  43  95   6 105  90  44 106  54  62  87  23  60  20  44   0  44\n",
            " 104  71  73  59  37  45  27  32   4   5  26  79  56  69  69  32  30  49\n",
            "  13  94  88   2  84 106 106  22  13  14  53  45  44  69  50  27 106  59\n",
            "  88  54  85  93  41  34  75  43  74   5  82 102  16  69  30  44 107  73\n",
            "  41   4  55  24  76  42  84 103  43  35  47  15  81  61  53  41  95   5\n",
            "   6  88  88  29  15  30  58  59   1  53  18  30  56  52  50  42  72  27\n",
            "  86  23  86  31  86  65  49  55  52  19   7  29   7  45 102  59  97  94\n",
            "  23  22 103  73   1  24  75  58  97   3  82  91   6  71  70  98  90  16\n",
            "  84  63  37   2  67  43  31  73  94  80  80  10  41  85   7 102  49  41\n",
            " 105  72  52  27  79  48  68  72  48   6   5  65  20  76  58  98  92  58\n",
            " 101 102  72  26  80  68   9  13   3  75  67  76  92  60  18 106  38   8\n",
            " 101  42  58  80  66  18  38 103  42  26  63  19  71  52  87  20  28  23\n",
            "  37 101  96  63   1   1  56  80  79 100  15  29  63  17  27  26  30   2\n",
            "  74  24  40  78  86  55  26  36   8  55  41  26  68   6  64  86  13  93\n",
            "   5  84 100  94  88 106  14  11  61  69  92  76   0  25  34  17  98  75\n",
            "  60  54 101  39  68  36  67  52  37  38  39  51   4 107  12  37  47  16\n",
            "  69  45  52  90  98  94  27  36 100  60  16  21 105  60  61  98  55  54\n",
            "  84  10  53  34  88  77  65  69  78  77  43  32  98  39  40  32   6  15\n",
            "  84  10  33  11 102   7  36  30  39  12  20  53  20 100 104  51  71  71\n",
            "  93  44  43  46]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOkW5_i308aA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import model_from_json, load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B3UDzMO1CNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"model.hdf5\")\n",
        "model.save_weights(\"model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmTE_eEY1E71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"model.h5\")\n",
        "loaded_model = load_model('model.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RavPkAy3JsuA",
        "colab_type": "text"
      },
      "source": [
        "It is seen that both VGG16 transfer learning model and custom built model provides better accuracy when compared to Inception model."
      ]
    }
  ]
}